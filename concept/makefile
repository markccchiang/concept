# This is the makefile for the CONCEPT code. Preferebly you should not interact
# with this file directly, but rather through the run script.
# It is expected that you call this makefile with the paramsfile=filename option.
# Otherwise $(params_default) will be used as parameterfile.

# Use the bash shell
SHELL = /bin/bash


##############################
# Specification of filenames #
##############################
# Modules which should be cythonized and compiled
pyfiles = communication ewald graphics gravity integration IO mesh params species timeloop units
# The default parameterfile to use (never needed when invoked via the run script)
params_default = params/default
# Filename of the .pyx preprocessor script
pyxpp = pyxpp.py
# Modules imported by the commons module
commons_imports = units params species IO
# Modules which import the commons module
do_import_commons = communication ewald graphics gravity integration IO mesh species timeloop
# List of files generated by running the code, which should be deleted by distclean
files_auxiliary = output logs __pycache__ jobscript .ewald_gridsize* .fftw_wisdom_gridsize*


################################################
# Environment information from the .paths file #
################################################
paths=$(shell this_dir="$$( cd "$$( dirname "$${BASH_SOURCE[0]}" )" && pwd )"; \
          curr="$${this_dir}"; \
          while [ 1 ]; do \
              if [ -f "$${curr}/.paths" ]; then \
                  paths="$${curr}/.paths"; \
                  break; \
              fi; \
              if [ "$${curr}" == "/" ]; then \
                  paths='fail'; \
                  break; \
              fi; \
              curr="`dirname \"$${curr}\"`"; \
          done; \
          echo "$${paths}")
ifeq ($(paths), fail)
    $(error Could not find .paths file)
endif
miniconda_dir  = $(shell source $(paths); echo $${miniconda_dir})
openmpi_dir    = $(shell source $(paths); echo $${openmpi_dir})
fftw_dir       = $(shell source $(paths); echo $${fftw_dir})
gsl_dir        = $(shell source $(paths); echo $${gsl_dir})
python         = $(shell source $(paths); echo $${python})
python_incl_m  = $(shell source $(paths); echo $${python_incl_m})
cython         = $(shell source $(paths); echo $${cython})


########################################
# Settings for compilation and linking #
########################################
# Options passed when cynthonizing .pyx files
cythonflags = -3 -a -o
# Includes
miniconda_incl = -I$(python_incl_m)
openmpi_incl   = -I$(openmpi_dir)/include
fftw_incl      = -I$(fftw_dir)/include
gsl_incl       = -I$(gsl_dir)/include
includes = $(miniconda_incl) $(openmpi_incl) $(fftw_incl) $(gsl_incl)
# Compiler options
CC = $(openmpi_dir)/bin/mpicc
mathoptimizations = -fassociative-math -fno-trapping-math -fno-signed-zeros  # Is this smart?
CFLAGS = -pthread -DNDEBUG -g -std=c99 -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC $(mathoptimizations) $(includes)
# Libraries to link
miniconda_libs = -L$(miniconda_dir)/lib -L$(python)m
openmpi_libs   = -L$(openmpi_dir)/lib -Wl,"-rpath=$(openmpi_dir)/lib" -lmpi
fftw_libs      = -L$(fftw_dir)/lib -Wl,"-rpath=$(fftw_dir)/lib" -lfftw3_mpi -lfftw3
gsl_libs       = -L$(gsl_dir)/lib -Wl,"-rpath=$(gsl_dir)/lib" -lgsl -lgslcblas
LDLIBS = $(miniconda_libs) $(openmpi_libs) $(fftw_libs) $(gsl_libs) -lm
# Linker options
LDFLAGS = -pthread -shared


################################
# Preprocess the params module #
################################
# If no paramsfile argument is supplied, the default parameterfile will be used
ifndef $(paramsfile)
    paramsfile=$(params_default)
endif
# Force execution of the params.py target if the parameterfile passed as $(paramsfile)
# differ from that of the last run. Here, 37 is 1 plus the length of the string
# "# The following is an exact copy of ", used in the params.py target.
ifndef $(rebuild_params)
    rebuild_params="no"
endif
.PHONY := $(shell if [ -f params.py ] && [ "$(paramsfile)" != "$(shell head -n 1 \
          params.py 2> /dev/null | cut -c 37-)" ] && [ $(rebuild_params) == "no" ] ; then \
          $(MAKE) --always-make paramsfile=$(paramsfile) rebuild_params="yes" params.py; fi)
ifneq ($(.PHONY),)
    $(info )
    $(info $(strip $(.PHONY)))
endif


###########
# Targets #
###########
# Make everything
all: $(addsuffix .so, $(pyfiles))
	@# This suppresses "make: Nothing to be done for `all'."

# Make shared object Python modules (the rule is the same as the builtin implicit rule for .o to executable)
$(addsuffix .so, $(pyfiles)): %.so: %.o
	$(CC) $(LDFLAGS) $< $(LOADLIBES) $(LDLIBS) -o $@

# Compile c source files into object files
$(addsuffix .o, $(pyfiles)): %.o: %.c

# Cythonize .pyx and .pxd files into c source files
$(addsuffix .c, $(pyfiles)): %.c: %.pyx
	@printf "\n\033[1m\033[93mBuilding the $(subst .c,,$@) module\033[0m\n"
	$(cython) $(cythonflags) $@ $<

# Use declarations in .pyx files to create .pxd files
$(addsuffix .pxd, $(pyfiles)): %.pxd: %.pyx
	@$(python) $(pyxpp) $< $(paramsfile) "pxd"

# Transform .py files into .pyx files
$(addsuffix .pyx, $(pyfiles)): %.pyx: %.py
	@cp $< $@
	@$(python) $(pyxpp) $@ $(paramsfile) "pyx"

# Copy the specified parameterfile to params.py and inserts a header, telling which parameterfile it is a
# copy of. Also include imports of some useful numpy functions and constants, import everything from the
# units module and the paths from the .paths file in the header, enabling the use of math, units and absolute
# paths in parameter files. Lastly, write pxd information directly to the params.py so that the pyxpp script
# can make a pxd file.
params.py: $(paramsfile) $(MAKEFILE_LIST)
	@echo
	@echo "Processing parameters from $(paramsfile)"
	@cp $(paramsfile) $@
	@sed -i '1i# The following is an exact copy of $(paramsfile)\
	# Import useful numpy functions and constants\
	from numpy import abs, arange, arccos, arccosh, arcsin, arcsinh, arctan, arctanh, ceil, cos, cosh, e, exp, floor, linspace, loadtxt, log, log10, log2, pi, sqrt, sin, sinh, tan, tanh\
	# Get access to the absolute paths stored in the .paths file\
	import imp, os\
	top_dir = "."\
	ls_prev = []\
	possible_root_dir = 0\
	while True:\
	    ls = os.listdir(top_dir)\
	    possible_root_dir = (possible_root_dir + 1) if ls == ls_prev else 0\
	    if possible_root_dir == 3:  # 3 ../ and still the same files. "Must" be /.\
	        raise Exception("Cannot find the .paths file!")\
	    if ".paths" in ls:\
	        break\
	    top_dir = "../" +  top_dir\
	    ls_prev = ls\
	paths_module = imp.load_source("paths", top_dir + "/.paths")\
	paths = paths_module.__dict__\
	# Include the directory of the parameter file as "params_dir"\
	paths["params_dir"] = os.path.dirname("$(paramsfile)")\
	# Seperate but equivalent imports in pure Python and Cython\
	import cython\
	if not cython.compiled:\
	    # Import units from the non-compiled .py file\
	    units = imp.load_source("units", "units.py")\
	    for key, value in units.__dict__.items():\
	        if isinstance(key, str):\
	            try:\
	                exec(key + "= value")\
	            except:\
	                pass\
	else:\
	    # Lines in triple quotes will be executed in the .pyx file\
	    """\
	    from units cimport *\
	    """\
	#Original parameter file below\n' $@
	@# Append pxd information to the params file
	@sed -i '$$a\\n\
	# The pxd content of this file. The pyxpp script will recognize\
	# it and put it in the pxd file.\
	pxd = """\
	# Input/output\
	str IC_file\
	str output_dir\
	str output_type\
	str snapshot_base\
	tuple outputtimes\
	# Numerical parameters\
	double boxsize\
	int ewald_gridsize\
	ptrdiff_t PM_gridsize\
	double P3M_scale\
	double P3M_cutoff\
	dict softeningfactors\
	double Δt_factor\
	# Cosmological parameters\
	double H0\
	double Ωm\
	double ΩΛ\
	double a_begin\
	# Graphics\
	str framefolder\
	str liveframe\
	str image_format\
	size_t framespace\
	str remote_liveframe\
	str protocol\
	# Simulation options\
	bint use_Ewald\
	dict kick_algorithms\
	"""\n' $@


###########################
# Additional dependencies #
###########################
# All c source files depend on their own header file
$(addsuffix .c, $(pyfiles)): %.c: %.pxd
# Lots of modules import the commons module, but it itself has imports
$(addsuffix .c, $(do_import_commons)): $(addsuffix .pxd, $(commons_imports))
# The .pyx files are generated with the pyxpp script
$(addsuffix .pyx, $(pyfiles)): $(pyxpp)
# The .pyx files get a copy of commons.py dumped into them.
# They are generated by the pyxpp script.
# Since creating .pyx files is the first step in the make process,
# they should depend on this makefile itself.
$(addsuffix .pyx, $(pyfiles)): commons.py $(pyxpp) $(MAKEFILE_LIST)
# Dependencies due to imports
communication.c:
ewald.c: mesh.pxd
graphics.c: fft.c
gravity.c: ewald.pxd communication.pxd mesh.pxd
integration.c:
IO.c: species.pxd communication.pxd
mesh.c: communication.pxd
species.c: gravity.pxd communication.pxd
timeloop.c: species.pxd IO.pxd integration.pxd graphics.pxd
units.c:


###################
# Cleanup targets #
###################
# Remove all compiled files
clean:
	$(RM) $(foreach ext, pyx pxd c o so html,$(addsuffix .$(ext), $(pyfiles))) params.py
# Remove compiled modules only
clean_so:
	$(RM) $(addsuffix .so, $(pyfiles))
# Remove files produced by running tests
clean_tests:
	$(addsuffix ;, ./$(shell find tests/ -type f -name 'clean'))
# Remove files generated by running the program
clean_auxiliary:
	$(RM) -r $(files_auxiliary)
# Restore all unnecessary files, leaving the program in a distribution ready state
distclean: clean clean_tests clean_auxiliary

