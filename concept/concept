#!/usr/bin/env bash

# This file is part of CO𝘕CEPT, the cosmological 𝘕-body code in Python.
# Copyright © 2015-2016 Jeppe Mosgaard Dakin.
#
# CO𝘕CEPT is free software: You can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# CO𝘕CEPT is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with CO𝘕CEPT. If not, see http://www.gnu.org/licenses/
#
# The auther of CO𝘕CEPT can be contacted at dakin(at)phys.au.dk
# The latest version of CO𝘕CEPT is available at
# https://github.com/jmd-dk/concept/



# This script runs the CO𝘕CEPT code.
# Run the script with the -h option to get help.

# List of remote queues and number of CPUs per node
queues=()
ppns=()

# If this file is being sourced, backups of 'this_file' and 'this_dir'
# is needed not to alter the values of these variables.
this_file_backup="${this_file}"
this_dir_backup="${this_dir}"

# Absolute paths to this file and its directory
this_file="$(readlink -f "${BASH_SOURCE[0]}")"
this_dir="$(dirname "${this_file}")"

# The user's current working directory
if [ -z "${workdir}" ]; then
    export workdir="$(pwd)"
fi

# For the terminal to be able to print Unicode characters correctly,
# the terminal charset need to be compatible.
export LC_CTYPE="en_US.UTF-8"
# Set the terminal if unset or broken
if [ -z "${TERM}" ] || [ "${TERM}" == "dumb" ]; then
    export TERM="linux"
fi

# ANSI/VT100 escape sequences
esc="\x1b"
esc_normal="${esc}[0m"
esc_bold="${esc}[1m"
esc_italic="${esc}[3m"
esc_no_italic="${esc}[23m"
esc_red="${esc}[91m"

# Load paths from the .paths file
curr="${this_dir}"
while :; do
    if [ -f "${curr}/.paths" ]; then
        source "${curr}/.paths"
        break
    fi
    if [ "${curr}" == "/" ]; then
        # Print out error message and exit
        printf "${esc_bold}${esc_red}Could not find the .paths file!${esc_normal}\n" >&2
        exit 1
    fi
    curr="$(dirname "${curr}")"
done

# Function for printing colored messages
colorprint()
{
# Arguments: Message, color
"${python}" -c "
import sys
from blessings import Terminal
terminal = Terminal(force_styling=True)
print(terminal.bold_${2}('${1}'), file=(sys.stderr if '${2}' == 'red' else sys.stdout))"
}

# Function for printing out a nice CO𝘕CEPT logo
print_logo()
{
    logo='
   ____     ____             __  ____    _____   ____   _____  
  / __ \   / __ \     /\    / / / __ \  |  ___| |  _ \ |_   _| 
 | /  \_| | /  \ |   /  \  / / | /  \_| | |__   | |_) |  | |   
 ||    _  ||    ||  / /\ \/ /  ||    _  |  __|  |  __/   | |   
 | \__/ | | \__/ | / /  \  /   | \__/ | | |___  | |      | |   
  \____/   \____/ /_/    \/     \____/  |_____| |_|      |_|   
═══════════════════════════════════════════════════════════════
'
    # Plot the logo via Python's matplotlib.
    # This uses up the the 16th and 17th color of the terminal.
    "${python}" -c "
import numpy as np, matplotlib
# Apply colormap
colors = ([0.09, 0.84, 0.05], [0.98, 0.47, 0.20])
for i, color in enumerate(colors):
    colorhex = matplotlib.colors.rgb2hex(color)
    print('\\x1b]4;{};rgb:{}/{}/{}\\x1b\\\\'
           .format(16 + i, colorhex[1:3], colorhex[3:5], colorhex[5:]), end='')
# Construct the colored logo
logo='''${logo}'''
logo = logo[1:-1]
rows = logo.split('\\n')
ANSI = []
for i, row in enumerate(rows):
    for j, c in enumerate(row):
        colornumber = 17 if i < 6 and 17 < j < 31 else 16
        ANSI.append('\\x1b[38;5;{}m{}'.format(colornumber, c))
    ANSI.append('\\x1b[0m\\n')
# Print the ANSI image
print(''.join(ANSI), end='')
     "
}
# Print out the logo the first time an execution reaches this point
if [ "${logo_printed}" != "True" ]; then
    print_logo
    export logo_printed="True"
fi

# Function for converting paths to absolute paths
absolute_path()
{
    # Arguments: Path, [working directory]
    local path="${1}"
    currdir="$(pwd)"
    if [ -n "${2}" ]; then
        cd "${2}"
    fi
    # Places backslashes before spaces.
    # These are needed when expanding tilde, but they will not persist.
    path="${path//[ ]/\\ }"
    # Expand tilde
    eval path="${path}"
    # Convert to absolute path
    path=$(readlink -m "${path}")
    if [ -z "${path}" ]; then
        colorprint "Cannot convert \"${1}\" to an absolute path!" "red"
        exit 1
    fi
    cd "${currdir}"
    # Print out result
    echo "${path}"
}

# Function for converting an absolute path to its "sensible" form.
# That is, this function returns the relative path with respect to the
# concept directory, if it is no more than one directory above the
# concept directory. Otherwise, return the absolute path back again.
sensible_path()
{
"${python}" -c "
path = '${1}'
from os.path import relpath
rel = relpath(path, '${concept_dir}')
print(path if rel.startswith('../../') else rel)"
}

# If this file is being sourced, return now
if [ "${BASH_SOURCE[0]}" != "${0}" ]; then
    this_file="${this_file_backup}"
    this_dir="${this_dir_backup}"
    return
fi

# Set up error trapping
ctrl_c()
{
    trap : 0
    exit 2
}
abort()
{
    colorprint "An error occurred!" "red"
    exit 1
}
trap 'ctrl_c' SIGINT
trap 'abort' EXIT
set -e

# Default values of command-line arguments
local_default="False"
main_default="${concept_dir}/main.py"
nprocs_default=1
params_default="None"
pure_python_default="False"
walltime_default=72

# Initial but illegal values of some command-line arguments,
# for testing whether these arguments have been supplied.
nprocs_unspecified="-1"
params_unspecified="__none__"
queue_unspecified="__none__"
test_unspecified="__none__"
util_unspecified="__none__"

# Change to the concept code directory
cd "${concept_dir}"

# On some systems, libpng finds a wrong version of the zlib shared
# library. To fix this we export the zlib library at run time.
export LD_LIBRARY_PATH="${zlib_dir}/lib:${LD_LIBRARY_PATH}"

# Use Python's argparse module to handle command-line arguments
argparse_success="yes"
args=$("${python}" -c "
import argparse, sys
# Function which checks whether input is a
# representation of a positive integer.
def positive_int(value):
    def raise_argparse_exception():
        raise argparse.ArgumentTypeError(\"invalid positive int value: '{}'\".format(value))
    try:
        value = eval(value)
        value = float(value)
    except:
        raise_argparse_exception()
    if value != int(value):
        raise_argparse_exception()
    value = int(value)
    if value < 1:
        raise_argparse_exception()
    return value
# Setup command-line arguments
parser = argparse.ArgumentParser(prog='$(basename ${this_file})',
                                 description='Run the CO𝘕CEPT code')
parser.add_argument('-m', '--main',
                    help=('entry point of the code. '
                          'Can be a Python filename or command.'),
                    default='${main_default}',
                    )
parser.add_argument('-n', '--nprocs',
                    help='number of processes',
                    type=positive_int,
                    default=${nprocs_unspecified},
                    )
parser.add_argument('-p', '--params',
                    help='parameterfile to use',
                    default='${params_unspecified}',
                    )
parser.add_argument('-q', '--queue',
                    help=('queue for submission of the remote job. '
                          'If omitted the script will choose a queue'
                          'with a matching number of cores/node'),
                    default='${queue_unspecified}',
                    )
parser.add_argument('-t', '--test',
                    help=('run test TEST. TEST can be any subdirectory of the tests directory. '
                          'Use TEST=all to run all tests'),
                    default='${test_unspecified}',
                    )
parser.add_argument('-u', '--util',
                    nargs='+',
                    help='run utility UTIL. UTIL can be any executable in the utilities directory',
                    default=['${util_unspecified}']*2,  # One for util, one for util_args
                    )
parser.add_argument('-w', '--walltime',
                     help='set the PBS walltime in whole hours',
                     type=positive_int,
                     default=${walltime_default},
                     )
parser.add_argument('--local',
                    help='force the run to be done locally, without submitting it via PBS',
                    default=${local_default},
                    action='store_true',
                    )
parser.add_argument('--pure-python',
                    help='run in pure Python mode',
                    default=${pure_python_default},
                    action='store_true',
                    )
# Enables Python to write directly to screen (stderr)
# in case of help request.
stdout_copy = sys.stdout
sys.stdout = sys.stderr
# Now do the actual argument parsing,
# including writing out the help message.
args, unknown_args = parser.parse_known_args()
# If a utility is to be used, arguments unknown to this script should
# be parsed on to the utility.
util_args = args.util[1:]
if args.util[0] != '${util_unspecified}':
    util_args += unknown_args
else:
    # Do print out error if invalid arguments are given
    # and no utility should be used.
    args = parser.parse_args()
# Reset stdout
sys.stdout = stdout_copy
# Print out the arguments.
# These will be captured in the Bash 'args' variable
print(  '  argparse_finished=yes'
      + '; main=\"{}\"'.format(args.main)
      + '; nprocs={}'.format(args.nprocs)
      + '; params=\"{}\"'.format(args.params)
      + '; queue={}'.format(args.queue)
      + '; test=\"{}\"'.format(args.test)
      + '; util=\"{}\"'.format(args.util[0])
      + '; util_args=({})'.format(\"'\" + \"' '\".join(util_args) + \"'\")  # Bash array
      + '; walltime={}'.format(args.walltime)
      + '; local={}'.format(args.local)
      + '; pure_python={}'.format(args.pure_python)
      )
" "$@" || echo "argparse_success=\"no\"")
# Evaluate the handled arguments into this scope
eval "${args}"
# Exit if argparse exited without finishing
if [ "${argparse_finished}" != "yes" ]; then
    # Python's argparse did not finish, either due to help being
    # asked for (and given) or invalid arguments.
    if [ "${argparse_success}" == "yes" ]; then
        # Help was asked for and given
        trap : 0
        exit 0
    else
        # Invalid arguments
        exit 1
    fi
fi

# Check whether the main "file" is really a string of commands
main_as_command="no"
if [[ "${main}" == *"print("* ]]; then
    main_as_command="yes"
fi

# Convert all supplied paths to absolute paths
if [ "${main_as_command}" == "no" ]; then
    main="$(absolute_path "${main}")"
fi
if [ "${params}" != "${params_unspecified}" ]; then
    params="$(absolute_path "${params}")"
fi
if [ "${test}" != "${test_unspecified}" ] && [ "${test}" != "all" ]; then
    test="${tests_dir}/$(basename "${test}")"
fi
if [ "${util}" != "${util_unspecified}" ]; then
    util="${utilities_dir}/$(basename "${util}")"
fi

# Do the supplied paths exist?
if [ "${main_as_command}" == "no" ] && [ ! -f "${main}" ]; then
    colorprint "Error: Entry point \"${main}\" does not exist!" "red"
    exit 1
fi
if [ "${params}" != "${params_unspecified}" ] && [ ! -f "${params}" ]; then
    colorprint "Error: Parameterfile \"${params}\" does not exist!" "red"
    exit 1
fi
if [ "${test}" != "${test_unspecified}" ] && [ "${test}" != "all" ] && [ ! -d "${test}" ]; then
    colorprint "Error: Test \"${test}\" does not exist!" "red"
    exit 1
fi
if [ "${util}" != "${util_unspecified}" ] && [ ! -f "${util}" ]; then
    colorprint "Error: Utility \"${util}\" does not exist!" "red"
    exit 1
fi

# Assigned values to unspecified parameters
running_test_or_util="False"
if [ "${util}" != "${util_unspecified}" ] || [ "${test}" != "${test_unspecified}" ]; then
    running_test_or_util="True"
fi
if [ "${nprocs}" == "${nprocs_unspecified}" ]; then
    nprocs="${nprocs_default}"
    if [ "${running_test_or_util}" == "False" ]; then
        echo "Number of processes not specified - Will use ${nprocs}"
    fi
fi
if [ "${params}" == "${params_unspecified}" ]; then
    params="${params_default}"
    if [ "${running_test_or_util}" == "False" ]; then
        echo "Parameterfile not specified - Will use default parameters"
    fi
fi

# If a test is to be run, run it and exit
if [ "${test}" != "${test_unspecified}" ]; then
    if [ "${test}" == "all" ]; then
        trap : 0
        for dir in "${tests_dir}/"*/; do
            dir=${dir%*/}
            colorprint "\nRunning $(basename ${dir}) test" "yellow"
            "${dir}/run_test"
        done
        colorprint "\nAll tests ran successfully" "green"
    else
        colorprint "Running $(basename ${test}) test" "yellow"
        trap : 0
        "${test}/run_test"
    fi
    exit 0
fi

# Compile or do cleanup from last compilation
if [ "${pure_python}" == "True" ] ; then
    # Rename compiled Cython modules *.so to *.so_
    if ls "${concept_dir}/"*.so > /dev/null 2>&1; then
        (cd "${concept_dir}" && for f in *.so; do
                                    mv "${f}" "${f%.so}.so_"
                                done
         )
    fi
else
    # Rename compiled Cython modules *.so_ back to *.so
    # and compile with Cython.
    if ls "${concept_dir}/"*.so_ > /dev/null 2>&1; then
        (cd "${concept_dir}" && for f in *.so_; do
                                    mv "${f}" "${f%.so_}.so"
                                done
         )
    fi
    (cd "${concept_dir}" && make)
fi

# If a utility is to be run, run it and exit
if [ "${util}" != "${util_unspecified}" ]; then
    # If no argument was passed after the -u option,
    # util_ars should be empty.
    if [ "${util_args}" == '""' ]; then
        util_args=""
    fi
    # Export every command-line argument. These will be fed back into
    # this script when called from the utility.
    export main="${main}"
    export nprocs="${nprocs}"
    export params="${params}"
    export queue="${queue}"
    export test="${test}"
    export util="${util}"
    export walltime="${walltime}"
    local_flag=""
    if [ "${local}" == "True" ]; then
        local_flag="--local"
    fi
    export local_flag="${local_flag}"
    pure_python_flag=""
    if [ "${pure_python}" == "True" ]; then
        pure_python_flag="--pure-python"
    fi
    export pure_python_flag="${pure_python_flag}"
    colorprint "Running the $(basename ${util}) utility" "yellow"
    trap : 0
    if [ -z "${util_args[0]}" ] && [ ${#util_args[@]} == 1 ]; then
        called_from_concept="True" "${util}"
    else
        called_from_concept="True" "${util}" "${util_args[@]}"
    fi
    exit 0
fi

# Sensible paths (for clean printout)
if [ "${main_as_command}" == "no" ]; then
    main_rel="$(sensible_path ${main})"
else
    main_rel="${main}"
fi
params_rel="$(sensible_path ${params})"
logs_dir_rel="$(sensible_path ${logs_dir})"

# Prompt the user for the secure shell password,
# if the live render should be uploaded to a remote host.
args=($("${python}" -B -c "
import imp, os, pexpect, re, sys
from getpass import getpass
from time import sleep
# Import parameters from the commons module
globals().update(imp.load_source('commons', 'commons.py').__dict__)
# Ask for password if remote liverender is requested
scp_password = ''
scp_success = 'success'
if remote_liverender:
    # Create test file to be scp'ed
    test_filename = '${this_dir}/.scp_test'
    with open(test_filename, 'a'):
        pass
    # Spawn the interactive process
    cmd = 'scp \"{}\" \"{}\"'.format(test_filename, remote_liverender)
    scp_host = re.search('@(.*):', remote_liverender).group(1)
    scp_dist = re.search(':(.*)',  remote_liverender).group(1)
    expects = ['password.*',
               'passphrase.*',
               'continue connecting',
               pexpect.EOF,
               pexpect.TIMEOUT,
               ]
    print('\nThe latest render will continuously be scp\'ed to\n\"{}\" at {}'
           .format(scp_dist, scp_host), file=sys.stderr)
    child = pexpect.spawn(cmd, timeout=15, env={'SSH_ASKPASS': '',
                                                'DISPLAY'    : ''})
    # Interactions
    while True:
        n = child.expect(expects)
        if n < 2:
            # scp asks for password or passphrase. Prompt the user for it
            scp_password = getpass((child.before + child.after).decode('utf-8'))
            # Now supply scp with the password
            child.sendline(scp_password)
        elif n == 2:
            # scp cannot authenticate host. Connect anyway
            child.sendline('yes')
        elif n == 3:
            # 
            break
        else:
            child.kill(9)
            break
    child.close(force=True)
    os.remove(test_filename)
    # If the test scp did not go well, reset password and write error message
    if child.status:
        scp_password = ''
        scp_success = ('Warning: Could not establish connection to {}\\\n'
                       + \"Remote live renders will not be scp\\\'ed\"
                       ).format(scp_host)
# Print out the password/passphrase and whether the scp test was
# successful. These will be captured in the Bash 'args' variable.
print(scp_success.replace(' ', '~'),
      scp_password,
      )
" "params='${params}'"))
scp_success="${args[0]//\~/ }"
scp_password="${args[1]}"
if [ "${scp_success}" != "success" ]; then
    colorprint "${scp_success}" "red"
    sleep 10
fi

# Create the logs dir if it does not exist
mkdir -p "${logs_dir}"

# Determine whether this script is run locally or remotely via ssh.
# Always treat tests as if they were run locally.
remote="False"
if [ "${local}" == "False" ] && [ "${test}" == "${test_unspecified}" ] \
                             && ([ -n "${SSH_CLIENT}" ] || [ -n "${SSH_TTY}" ]); then
    remote="True"
fi

# Either stop doing further actions, submit job or run it locally
if [ ${#queues[@]} == 0 ] && [ "${remote}" == "True" ]; then
    # Run remotely but do not use PBS
    printf "The CO𝘕CEPT code is ready to be submitted\n"
    trap : 0
    exit 0
elif [ ${#queues[@]} -gt 0 ] && [ "${remote}" == "True" ]; then
    # Run remotely.
    # If no queue is explicitly chosen, find a queue for
    # which the job can utilize all CPUs on the nodes
    if [ "${queue}" == "${queue_unspecified}" ]; then
        for ((i = 0; i < ${#queues[@]}; i += 1)); do
            queue="${queues[i]}"
            ppn="${ppns[i]}"
            if [ $((${nprocs} % ${ppn})) == 0 ]; then
                break
            fi
        done
        if [ $((${nprocs} % ${ppn})) != 0 ]; then
            colorprint "Error: Job submission refused: The number of processes (${nprocs}) is not \
divisible by the number of cores per node in any queue" "red"
            exit 1
        fi
        nodes="$((${nprocs} / ${ppn}))"
    else
        # How many CPUs does the explicitly chosen queue have per node?
        ppn="None"
        for ((i = 0; i < ${#queues[@]}; i += 1)); do
            if [ "${queue}" == "${queues[${i}]}" ]; then
                ppn="${ppns[${i}]}"
                break
            fi
        done
        if [ "${ppn}" == "None" ] || [ -z "${ppn}" ] ; then
            colorprint "Error: The requested queue \"${queue}\" is not familiar to me." "red"
            colorprint "Please specify it in the \"queues\" and \"ppns\" variables." "red"
            exit 1
        fi
        nodes=$((${nprocs} / ${ppn}))
        # Check that the explicitly chosen queue can be run
        # with all the node's CPUs in use.
        if [ $((${nprocs} % ${ppn})) != 0 ]; then
            colorprint "Warning: The number of processes (${nprocs}) is not divisible by \
the number of cores per node (${ppn}) in queue ${queue}" "red"
            read -p "Submit anyway? [y/N] " yn
            case "${yn}" in
                [Yy]* ) ;;
                [Nn]* ) echo "Job submission refused"; trap : 0; exit 0;;
                ""    ) echo "Job submission refused"; trap : 0; exit 0;;
                *     ) echo "Job submission refused"; trap : 0; exit 0;;
            esac
            # Not every CPU pr. node should be used.
            # Find the right number.
            while [ ${ppn} -gt 1 ]; do
                ((ppn -= 1))
                if [ $((${nprocs} % ${ppn})) == 0 ]; then
                    nodes=$((${nprocs} / ${ppn}))
                    break
                fi
            done
        fi
    fi
    # Write a jobscript file
    printf "#!/usr/bin/env bash
#PBS -N CONCEPT:${params}:CONCEPT
#PBS -q ${queue}
#PBS -l nodes=${nodes}:ppn=${ppn}
#PBS -l walltime=${walltime}:00:00
#PBS -o /dev/null
#PBS -e /dev/null

# Change to the logs directory, so that autogenerated files will be dumped there
cd \"${logs_dir}\"

# Get the ID of the current job
jobid=\"\${PBS_JOBID%%.*}\"

# Set and export path environment variables
export PATH=\"${PATH}:\${PATH}\"
export LD_LIBRARY_PATH=\"${LD_LIBRARY_PATH}:\${LD_LIBRARY_PATH}\"

# On some systems, libpng finds a wrong version of the zlib shared
# library. To fix this we export the zlib library at run time.
export LD_LIBRARY_PATH=\"${zlib_dir}/lib:\${LD_LIBRARY_PATH}\"
# For the terminal to be able to print Unicode characters correctly,
# the terminal charset need to be compatible.
export LC_CTYPE=\"en_US.UTF-8\"
# Set the terminal if unset or broken
if [ -z \"\${TERM}\" ] || [ \"\${TERM}\" == \"dumb\" ]; then
    export TERM=\"linux\"
fi

# Source the concept script
source \"${concept}\"

# Print start messages
if [ \"${pure_python}\" == \"True\" ]; then
    colorprint \"Running CO𝘕CEPT in pure Python mode remotely on \$(hostname -f) \
as job \${jobid}\" \"yellow\" > \"${logs_dir}/\${jobid}\"
else
    colorprint \"Running CO𝘕CEPT remotely on \$(hostname -f) \
as job \${jobid}\" \"yellow\" > \"${logs_dir}/\${jobid}\"
fi
echo \"Entry point:   \\\\\"${main_rel}\\\\\"\"               >> \"${logs_dir}/\${jobid}\"
if [ \"${params_rel}\" == \"None\" ]; then
    echo \"Parameterfile: ${params_rel}\"                     >> \"${logs_dir}/\${jobid}\"
else
    echo \"Parameterfile: \\\\\"${params_rel}\\\\\"\"         >> \"${logs_dir}/\${jobid}\"
fi
echo \"Logfile:       \\\\\"${logs_dir_rel}/\${jobid}\\\\\"\" >> \"${logs_dir}/\${jobid}\"
echo \"Nr. of CPUs:   ${nprocs}\"                             >> \"${logs_dir}/\${jobid}\"

# Prepare Python options
if [ \"${main_as_command}\" == \"yes\" ]; then
    # Run as Python command
    main_as_library=\"${main}\"
    m_flag=\"-c\"
else
    if [ \"${pure_python}\" == \"True\" ]; then
        # Run as normal Python script
        main_as_library=\"${main}\"
        m_flag=\"\"
    else
        # Run as compiled library module
        main_as_library=\"$(basename "${main%.*}.so")\"
        m_flag=\"-m\"
    fi
fi

# Run the code. Both stdout and stderr are being logged to logs_dir/jobid,
# while the stderr alone is also logged to logs_dir/jobid_err.
(cd \"${concept_dir}\" && \"${mpiexec}\" \"${python}\" -B \${m_flag} \"\${main_as_library}\" \
\"params='${params}'\" \"scp_password='${scp_password}'\" \
>> \"${logs_dir}/\${jobid}\" 2>> >(tee -a \"${logs_dir}/\${jobid}_err\"))

# Run complete. Remove error log if empty
if [ -f \"${logs_dir}/\${jobid}_err\" ] && [ ! -s \"${logs_dir}/\${jobid}_err\" ]; then
    rm \"${logs_dir}/\${jobid}_err\"
else
    colorprint \"\\\nSome warnings/errors occured during CO𝘕CEPT run!\" \"red\" \
>> \"${logs_dir}/\${jobid}\" 2>&1
    colorprint \"Check the following error log for more information:\"  \"red\" \
>> \"${logs_dir}/\${jobid}\" 2>&1
    colorprint \"\\\\\"${logs_dir}/\${jobid}_err\\\\\"\"                \"red\" \
>> \"${logs_dir}/\${jobid}\" 2>&1
fi
" > "${this_dir}/jobscript"
    # Check for the qsub command
    qsub_path="$(which qsub 2> /dev/null || :)"
    if [ -z "${qsub_path}" ]; then
        colorprint "Error: Could not find the 'qsub' command. \
Is PBS installed and on the PATH?" "red"
        exit 1
    fi
    # Submit the remote job from within the logs directory,
    # so that autogenerated files will be dumped there.
    jobid=$(cd "${logs_dir}" && qsub "${this_dir}/jobscript")
    jobid="${jobid%.*}"
    colorprint "\nSubmitting job" "yellow"
    echo "Job ${jobid} submitted to queue ${queue}"
    echo "You can now kill (Ctrl-C) this script without cancelling the job"
    # Deactivate trap and call the watch script
    sleep 1
    trap : 0
    "${utilities_dir}/watch" "${jobid}"
else
    # Run locally.
    # Construct a jobid that does not conflict
    # with the content of the logs dir.
    jobid=0
    while :; do
        if [ ! -f "${logs_dir}/${jobid}" ]; then
            break
        fi
        ((jobid += 1))
    done
    # Print start message
    echo
    if [ "${pure_python}" == "True" ]; then
        colorprint "Running CO𝘕CEPT in pure Python mode" "yellow" | tee    "${logs_dir}/${jobid}"
    else
        colorprint "Running CO𝘕CEPT" "yellow"                     | tee    "${logs_dir}/${jobid}"
    fi
    echo "Entry point:   \"${main_rel}\""                         | tee -a "${logs_dir}/${jobid}"
    if [ "${params_rel}" == "None" ]; then
        echo "Parameterfile: ${params_rel}"                       | tee -a "${logs_dir}/${jobid}"
    else
        echo "Parameterfile: \"${params_rel}\""                   | tee -a "${logs_dir}/${jobid}"
    fi
    echo "Logfile:       \"${logs_dir_rel}/${jobid}\""            | tee -a "${logs_dir}/${jobid}"
    echo "Nr. of CPUs:   ${nprocs}"                               | tee -a "${logs_dir}/${jobid}"
    # Prepare Python options
    if [ "${main_as_command}" == "yes" ]; then
        # Run as Python command
        main_as_library="${main}"
        m_flag="-c"
    else
        if [ "${pure_python}" == "True" ]; then
            # Run as normal Python script
            main_as_library="${main}"
            m_flag=""
        else
            # Run as compiled library module
            main_as_library="$(basename "${main%.*}.so")"
            m_flag="-m"
        fi
    fi
    # Run the code. Print stdout and stderr to the terminal while at the
    # same time logging them to logs_dir/jobid. The stderr alone is also
    # logged to logs_dir/jobid_err.
    (("${mpiexec}" -n "${nprocs}"                               \
                   "${python}" -B                               \
                               ${m_flag} "${main_as_library}"   \
                               "params='${params}'"             \
                               "scp_password='${scp_password}'" \
     | tee -a "${logs_dir}/${jobid}";                           \
       echo "${PIPESTATUS[0]}" > "${logs_dir}/.exit_code"       \
     ) 3>&1 1>&2 2>&3 | tee -a "${logs_dir}/${jobid}"           \
                               "${logs_dir}/${jobid}_err") 3>&1 1>&2 2>&3
    sleep 1
    concept_exit_code="$(cat "${logs_dir}/.exit_code")"
    # Cleanup
    rm -f "${logs_dir}/.exit_code"
    # Run complete. Remove error log if empty
    if [ -f "${logs_dir}/${jobid}_err" ] && [ ! -s "${logs_dir}/${jobid}_err" ]; then
        rm "${logs_dir}/${jobid}_err"
    else
        colorprint "\nSome warnings/errors occured during CO𝘕CEPT run!\n\
Check the following error log for more information:\n\
\"${logs_dir}/${jobid}_err\"" "red" 2>&1 | tee -a "${logs_dir}/${jobid}" 1>&2
    fi
    # If the CO𝘕CEPT run exited erroneously, exit now
    if [ "${concept_exit_code}" != "0" ]; then
        exit 1
    fi
    # Deactivate trap before exiting
    trap : 0
fi
