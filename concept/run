#!/usr/bin/env bash

# This file is part of CONCEPT, the cosmological N-body code in Python.
# Copyright (C) 2015 Jeppe Mosgard Dakin.
#
# CONCEPT is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# CONCEPT is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with CONCEPT. If not, see http://www.gnu.org/licenses/
#
# The auther of CONCEPT can be contacted at
# jeppe.mosgaard.dakin(at)post.au.dk
# The latest version of CONCEPT is available at
# https://github.com/jmd-dk/concept/



# This script runs the CONCEPT code.
# Run the script with the -h option to get help

# If this file is being sourced, backups of 'this_file' and 'this_dir'
# is needed not to alter the values of these variables.
this_file_backup="${this_file}"
this_dir_backup="${this_dir}"

# Absolute paths to this file and its directory
this_file="$(readlink -f "${BASH_SOURCE[0]}")"
this_dir="$(dirname "${this_file}")"

# ANSI/VT100 escape sequences
esc="\x1b"
esc_normal="${esc}[0m"
esc_bold="${esc}[1m"
esc_italic="${esc}[3m"
esc_no_italic="${esc}[23m"
esc_red="${esc}[91m"

# Load paths from the .paths file
curr="${this_dir}"
while :; do
    if [ -f "${curr}/.paths" ]; then
        source "${curr}/.paths"
        break
    fi
    if [ "${curr}" == "/" ]; then
        # Print out error message and exit
        printf "${esc_bold}${esc_red}Could not find the .paths file!${esc_normal}\n" >&2
        exit 1
    fi
    curr="$(dirname "${curr}")"
done

# Function for printing colored messages
terminal_CONCEPT="CO${esc_italic}N${esc_no_italic}CEPT"
colorprint()
{
# Arguments: Message, color
${python} -c "import sys
from blessings import Terminal
terminal = Terminal(force_styling=True)
msg='${1}'.replace('CONCEPT', '${terminal_CONCEPT}')
print(terminal.bold_${2}(msg), file=(sys.stderr if '${2}' == 'red' else sys.stdout))"
}

# Function for converting paths to absolute paths
absolute()
{
    local path="${1}"
    local path_backup="${path}"
    path="${path//[ ]/\\ }"        # Places backslashes before spaces. These are needed when expanding tilde, but they will not persist!
    eval path="${path}"            # Expand tilde
    path=$(readlink -m "${path}")  # Convert to absolute path
    if [ -z "${path}" ]; then
        colorprint "Cannot convert \"${path_backup}\" to an absolute path!" "red"
        exit 1
    fi
    echo "${path}"
} 

# If this file is being sourced, return now
if [ "${BASH_SOURCE[0]}" != "${0}" ]; then
    this_file="${this_file_backup}"
    this_dir="${this_dir_backup}"
    return
fi

# Default values of command-line arguments
nprocs=1
params="None"  #"${this_dir}/params/default"
main="${concept_dir}/main.py"
pure_python=0
walltime=72
# List of remote queues and number of CPU per node. The first queue is the default queue 
queues=(q8n q8 q4)
ppns=(8 8 4)
# Should PBS be used to submit remote jobs?
use_PBS=1

# Change to the concept code directory
cd "${concept_dir}"
# On some systems, libpng finds wrong versions of the zlib shared
# library. To fix this we export the zlib library at run time.
export LD_LIBRARY_PATH="${zlib_dir}/lib:${LD_LIBRARY_PATH}"

# Use Python's argparse module to handle command line arguments
args=($(${python} -B -c "
import argparse
import sys
from os.path import basename, dirname
# Enables Python to write directly to screen when asked for help
if any(h in sys.argv for h in ['-h', '--he', '--hel', '--help']):
    sys.stdout = sys.stderr
# Set the filename of the script
sys.argv[0] = '${this_file}'
# Setup command-line arguments
parser = argparse.ArgumentParser(description='Run the CONCEPT code.')
parser.add_argument('--local',
                    help='Force the run to be done locally, without submitting it via PBS',
                    default=False,
		            action='store_true',
                    )
parser.add_argument('-m', '--main',
                    help='entry point of the code',
                    default='${main}',
                    )
parser.add_argument('-n', '--nprocs',
                    help='number of processes',
                    type=int,
                    default=${nprocs},
                    )
parser.add_argument('-p', '--params',
                    help='parameterfile to use',
                    default='${params}',
                    )
parser.add_argument('--pure-python',
                    help='run in pure Python mode',
                    default=${pure_python},
                    action='store_true',
                    )
parser.add_argument('-t', '--test',
                    help='run test TEST. TEST can be any subdirectory of the tests directory. Use TEST=all to run all tests',
                    default='none',
                    )
parser.add_argument('-q', '--queue',
                    help='Queue for submission of the remote job. If omitted the script will try to choose the best.',
                    default='none',
                    )
parser.add_argument('-w', '--walltime',
                     help='Set the PBS walltime in whole hours',
                     type=int,
                     default=${walltime},
                     )
args = parser.parse_args()
# Warnings when basic parameters are not supplied
unspecified_nprocs = False
unspecified_params = False
arg = '--nprocs'
if not any(n in sys.argv for n in ['-n'] + [arg[:i] for i in range(4, len(arg) + 1)]):
    unspecified_nprocs = True
arg = '--params'
if not any(p in sys.argv for p in ['-p'] + [arg[:i] for i in range(4, len(arg) + 1)]):
    if basename(dirname(args.main)) == 'tests':
        # Running a test but no parameterfile specified!
        args.params = dirname(args.main) + '/params_' + basename(args.main)
    else:
        unspecified_params = True
# Print out the arguments.
# These will be captured in the bash 'args' variable
print(args.nprocs,
      args.params,
      args.main,
      int(args.pure_python),
      int(unspecified_nprocs),
      int(unspecified_params),
      args.test,
      args.walltime,
      args.queue,
      int(args.local),
      )
" "$@"))
nprocs="${args[0]}"
params="${args[1]}"
main="${args[2]}"
pure_python="${args[3]}"
unspecified_nprocs="${args[4]}"
unspecified_params="${args[5]}"
test="${args[6]}"
walltime="${args[7]}"
queue="${args[8]}"
local="${args[9]}"
if [ "${#args[@]}" -ne 10 ]; then
    colorprint "Error: Not every command line argument was gracefully dealt with!" "red"
    exit 1
fi

# Set up error trapping
ctrl_c()
{
    trap : 0
    exit 2
}
abort()
{
    colorprint "An error occurred!" "red"
    exit 1
}
trap 'ctrl_c' SIGINT
trap 'abort' EXIT
set -e

# Convert all supplied paths to absolute paths
params="$(absolute "${params}")"
main="$(absolute "${main}")"
if [ "${test}" != "none" ] && [ "${test}" != "all" ]; then
    test="${concept_dir}/tests/$(basename "${test}")"
fi

# Do the parameterfile, the main file and the test file exist?
if [ "${unspecified_params}" == 0 ] && [ ! -f "${params}" ]; then
    colorprint "Error: Parameterfile \"${params}\" does not exist!" "red"
    exit 1
fi
if [ ! -f "${main}" ]; then
    colorprint "Error: Entry point \"${main}\" does not exist!" "red"
    exit 1
fi
if [ "${test}" != "none" ] && [ "${test}" != "all" ] && [ ! -d "${test}" ]; then
    colorprint "Error: Test \"${test}\" does not exist!" "red"
    exit 1
fi

# If a test is to be run, run it and exit
if [ "${test}" != "none" ]; then
    trap : 0
    if [ "${test}" == "all" ]; then
        for dir in "${concept_dir}/tests/"*/; do
            dir=${dir%*/}
            colorprint "\nRunning $(basename ${dir}) test" "yellow"
            "${dir}/run_test"
        done
        colorprint "All tests ran successfully" "green"
    else
        colorprint "Running $(basename ${test}) test" "yellow"
        "${test}/run_test"
    fi
    exit 0
fi

# Relative path to the main and parameter, for clean printout
main_rel=$(${python}   -c "from os.path import relpath; rel = relpath('${main}',   '${concept_dir}'); print(rel if not rel.startswith('../../') else '${main}')")
params_rel=$(${python} -c "from os.path import relpath; rel = relpath('${params}', '${concept_dir}'); print(rel if not rel.startswith('../../') else '${params}')")

# Printout assigned values for unspecified parameters
if [ "${unspecified_nprocs}" == 1 ]; then
    echo "Number of processes not specified - Will use ${nprocs}"
fi
if [ "${unspecified_params}" == 1 ]; then
    echo "Parameterfile not specified - Will use default parameters"
fi

# Prompt the user for the secure shell password,
# if the live render should be uploaded to a remote host.
args=($("${python}" -B -c "
import os, pexpect, re, sys
from getpass import getpass
from time import sleep
# Import parameters from the commons module
from commons import *
# Ask for password if remote liverender is requested
scp_password = ''
scp_success = 'success'
if remote_liverender:
    # Create test file to be scp'ed
    test_filename = '${this_dir}/.scp_test'
    with open(test_filename, 'a'):
        pass
    # Spawn the interactive process
    cmd = 'scp \"{}\" \"{}\"'.format(test_filename, remote_liverender)
    scp_host = re.search('@(.*):', remote_liverender).group(1)
    scp_dist = re.search(':(.*)',  remote_liverender).group(1)
    expects = ['password.*',
               'passphrase.*',
               'continue connecting',
               pexpect.EOF,
               pexpect.TIMEOUT,
               ]
    print('\nThe latest render will continuously be scp\'ed to\n\"{}\" at {}'
           .format(scp_dist, scp_host), file=sys.stderr)
    child = pexpect.spawn(cmd, timeout=15, env={'SSH_ASKPASS': '',
                                                'DISPLAY'    : ''})
    # Interactions
    while True:
        n = child.expect(expects)
        if n < 2:
            # scp asks for password or passphrase. Prompt the user for it
            scp_password = getpass((child.before + child.after).decode('utf-8'))
            # Now supply scp with the password
            child.sendline(scp_password)
        elif n == 2:
            # scp cannot authenticate host. Connect anyway
            child.sendline('yes')
        elif n == 3:
            # 
            break
        else:
            child.kill(9)
            break
    child.close(force=True)
    os.remove(test_filename)
    # If the test scp did not go well, reset password and write error message
    if child.status:
        scp_password = ''
        scp_success = ('Warning: Could not establish connection to {}\\\n'
                       + \"Remote live renders will not be scp\\\'ed\"
                       ).format(scp_host)
# Print out the password/passphrase and whether the scp test was
# successful. These will be captured in the bash 'args' variable.
print(scp_success.replace(' ', '~'),
      scp_password,
      )
" "params='${params}'"))
scp_success="${args[0]//\~/ }"
scp_password="${args[1]}"
if [ "${scp_success}" != "success" ]; then
    colorprint "${scp_success}" "red"
    sleep 10
fi

# Compile or do cleanup from last compilation
if [ "${pure_python}" -eq 0 ] ; then
    # Rename compiled Cython modules *.so_ back to *.so and compile with Cython
    if ls "${concept_dir}/"*.so_ > /dev/null 2>&1; then
        (cd "${concept_dir}" && for f in *.so_; do mv "${f}" "${f%.so_}.so"; done)
    fi
    (cd "${concept_dir}" && make)
else
    # Rename compiled Cython modules *.so to *.so_
    if ls "${concept_dir}/"*.so > /dev/null 2>&1; then
        (cd "${concept_dir}" && for f in *.so; do mv "${f}" "${f%.so}.so_"; done)
    fi
fi

# Create the logs dir if it does not exist
mkdir -p "${concept_dir}/logs"

# Determine whether this script is run locally or remotely via ssh.
# Always treat tests as if they were run locally.
if [ "${local}" == 0 ] && [ "${test}" == "none" ] && ([ -n "${SSH_CLIENT}" ] || [ -n "${SSH_TTY}" ]); then
    remote=1
else
    remote=0
fi

# Either stop doing further actions, submit job or run it locally
if [ "${use_PBS}" -eq 0 ] && [ "${remote}" -eq 1 ]; then
    # Run remotely but do not use PBS
    printf "The ${terminal_CONCEPT} code is ready to be submitted"
    trap : 0
elif [ "${use_PBS}" -eq 1 ] && [ "${remote}" -eq 1 ]; then
    # Run remotely.
    # If no queue is explicitly chosen, use one with enough free nodes
    if [ "${queue}" == "none" ]; then
        # The first queue in the list is the default queue
        queue="${queues[0]}"
        ppn="${ppns[0]}"
        # Change to the queue that has enogh free CPUS to begin job immediately
        node_table=$(nodes)
        for i in $(eval echo "{0..${#queues[@]}}" | sed s/'\w*$'//); do
            free_nodes=$(echo "${node_table}" | grep -o -P "(?<= ${queues[${i}]}:).*(?= free)" | awk '{print $NF}')
            free_cpus=$(echo "$((${free_nodes} * ${ppns[${i}]}))")
            if [ "${free_cpus}" -ge "${nprocs}" ] && [ "$((${nprocs} % ${ppns[${i}]}))" -eq 0 ]; then
                queue="${queues[${i}]}"
                ppn="${ppns[${i}]}"
                break
            fi
        done
    else
        # How many CPUs does the explicitly chosen queue have per node?
        for i in $(eval echo "{0..${#queues[@]}}" | sed s/'\w*$'//); do
            if [ "${queue}" == "${queues[${i}]}" ]; then
                ppn="${ppns[${i}]}"
                break
            fi
        done
    fi
    # Check that the chosen queue can be run with all the node's CPUs in use
    if [ "$((${nprocs} % ${ppn}))" != 0 ]; then
        colorprint "Job submission refused:\nNo queue has the right amount of processors per node" "red"
        exit 1
    fi
    nodes="$((${nprocs} / ${ppn}))"
    # Write a jobscript file
    echo -e "#!/usr/bin/env bash
#PBS -N $(whoami):CONCEPT:$(basename ${params})
#PBS -q ${queue}
#PBS -l nodes=${nodes}:ppn=${ppn}
#PBS -l walltime=${walltime}:00:00
#PBS -o /dev/null
#PBS -e /dev/null

# Get the id of the current job
jobid=\"\${PBS_JOBID%.in1}\"

# Change to the logs directory, so that autogenerated files will be dumped there
cd \"${concept_dir}/logs\"

# Source the run script
source \"${this_file}\"

# Print start messages
if [ ${pure_python} -eq 0 ]; then
    colorprint \"Running CONCEPT remotely on \$(hostname -f) as job \${jobid}\" \"yellow\" > \"${concept_dir}/logs/\${jobid}\"
else
    colorprint \"Running CONCEPT in pure Python mode remotely on \$(hostname -f) as job \${jobid}\" \"yellow\" > \"${concept_dir}/logs/\${jobid}\"
fi
echo \"Entry point:   \\\"${main_rel}\\\"\"    >> \"${concept_dir}/logs/\${jobid}\"
echo \"Parameterfile: \\\"${params_rel}\\\"\"  >> \"${concept_dir}/logs/\${jobid}\"
echo \"Logfile:       \\\"logs/\${jobid}\\\"\" >> \"${concept_dir}/logs/\${jobid}\"
echo \"Nr. of CPUs:    ${nprocs}\"             >> \"${concept_dir}/logs/\${jobid}\"

# Prepare Python options
if [ \"${pure_python}\" == \"0\" ]; then
    # Run as compiled library module
    main_as_library=\"$(basename "${main%.*}.so")\"
    m_flag=\"-m\"
else
    # Run as normal Python script
    main_as_library=\"${main}\"
    m_flag=\"\"
fi

# Run the code. Both stdout and stderr are being logged to logs/jobid,
# while the stderr alone is also logged to logs/jobid_err.
(cd \"${concept_dir}\" && \"${mpiexec}\" \"${python}\" -B \${m_flag} \"\${main_as_library}\" \"${scp_password}\" >> \"${concept_dir}/logs/\${jobid}\" 2>> >(tee -a \"${concept_dir}/logs/\${jobid}_err\"))

# Run complete. Remove error log if empty
if [ -f \"${concept_dir}/logs/\${jobid}_err\" ] && [ ! -s \"${this_dir}/logs/\${jobid}_err\" ]; then
    rm \"${concept_dir}/logs/\${jobid}_err\"
else
    colorprint \"\\\nSome warnings/errors occured during CONCEPT run!\" \"red\" >> \"${concept_dir}/logs/\${jobid}\" 2>&1
    colorprint \"Check the following error log for more information:\" \"red\" >> \"${concept_dir}/logs/\${jobid}\" 2>&1
    colorprint \"\\\"${concept_dir}/logs/\${jobid}_err\\\"\" \"red\" >> \"${concept_dir}/logs/\${jobid}\" 2>&1
fi
" > "${this_dir}/jobscript"
    # Submit the remote job from within the logs directory, so that autogenerated files will be dumped there
    jobid=$(cd "${concept_dir}/logs" && qsub "${this_dir}/jobscript")
    jobid="${jobid%.in1}"
    colorprint "\nSubmitting job" "yellow"
    echo "Job ${jobid} submitted to queue ${queue}"
    echo "You can now kill (Ctrl-C) this script without cancelling the job"
    # Deactivate trap and call the watch script
    trap : 0
    "${concept_dir}/utilities/watch" "${jobid}"
else
    # Run locally.
    # Construct a jobid that does not conflict with the content of the logs dir
    jobid=0
    while :; do
        if [ ! -f "${concept_dir}/logs/${jobid}" ]; then
            break
        fi
        ((jobid += 1))
    done
    # Print start message
    echo
    if [ "${pure_python}" -eq 0 ]; then
        colorprint "Running CONCEPT" "yellow" | tee "${concept_dir}/logs/${jobid}"
    else
        colorprint "Running CONCEPT in pure Python mode" "yellow" | tee "${concept_dir}/logs/${jobid}"
    fi
    echo "Entry point:   \"${main_rel}\""   | tee -a "${concept_dir}/logs/${jobid}"
    if [ "${unspecified_params}" == 1 ]; then
        echo "Parameterfile: None" | tee -a "${concept_dir}/logs/${jobid}"
    else
        echo "Parameterfile: \"${params_rel}\"" | tee -a "${concept_dir}/logs/${jobid}"
    fi
    echo "Logfile:       \"logs/${jobid}\"" | tee -a "${concept_dir}/logs/${jobid}"
    echo "Nr. of CPUs:    ${nprocs}"        | tee -a "${concept_dir}/logs/${jobid}"
    # Prepare Python options
    if [ "${pure_python}" -eq 0 ] ; then
        # Run as compiled library module
        main_as_library="$(basename "${main%.*}.so")"
        m_flag="-m"
    else
        # Run as normal Python script
        main_as_library="${main}"
        m_flag=""
    fi
    # Run the code. Print stdout and stderr to the terminal while at the
    # same time logging them to logs/jobid. The stderr alone is also
    # logged to logs/jobid_err.
    "${mpiexec}" -n "${nprocs}" "${python}" -B ${m_flag} "${main_as_library}" "params='${params}'" "scp_password='${scp_password}'" 2> >(tee -a "${concept_dir}/logs/${jobid}_err") | tee -a "${concept_dir}/logs/${jobid}"
    # Get exit status of the above CONCEPT run
    concept_exit_status="${PIPESTATUS[0]}"
    # Run complete. Remove error log if empty
    if [ -f "${concept_dir}/logs/${jobid}_err" ] && [ ! -s "${concept_dir}/logs/${jobid}_err" ]; then
        rm "${concept_dir}/logs/${jobid}_err"
    else
        colorprint "\nSome warnings/errors occured during CONCEPT run!" "red" 2>&1 | tee -a "${concept_dir}/logs/${jobid}"
        colorprint "Check the following error log for more information:" "red" 2>&1 | tee -a "${concept_dir}/logs/${jobid}"
        colorprint "\"${concept_dir}/logs/${jobid}_err\"" "red" 2>&1 | tee -a "${concept_dir}/logs/${jobid}"
    fi
    # If the CONCEPT run exited erroneously, exit now
    if [ "${concept_exit_status}" != "0" ]; then
        exit 1
    fi
    # Deactivate trap before exiting
    trap : 0
fi
