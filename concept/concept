#!/usr/bin/env bash

# This file is part of CO𝘕CEPT, the cosmological 𝘕-body code in Python.
# Copyright © 2015-2017 Jeppe Mosgaard Dakin.
#
# CO𝘕CEPT is free software: You can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# CO𝘕CEPT is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with CO𝘕CEPT. If not, see http://www.gnu.org/licenses/
#
# The auther of CO𝘕CEPT can be contacted at dakin(at)phys.au.dk
# The latest version of CO𝘕CEPT is available at
# https://github.com/jmd-dk/concept/



# This script runs the CO𝘕CEPT code.
# Run the script with the -h option to get help.

# Unless this file is being sourced,
# automatically export all variables when set.
being_sourced="True"
if [ "${BASH_SOURCE[0]}" == "${0}" ]; then
    being_sourced="False"
fi
if [ "${being_sourced}" == "False" ]; then
    set -a
fi

# List of remote queues and number of CPUs per node
queues=()
ppns=()

# If this file is being sourced, backups of 'this_file' and 'this_dir'
# is needed not to alter the values of these variables.
this_file_backup="${this_file}"
this_dir_backup="${this_dir}"

# Absolute paths to this file and its directory
this_file="$(readlink -f "${BASH_SOURCE[0]}")"
this_dir="$(dirname "${this_file}")"

# The user's current working directory
if [ -z "${workdir}" ]; then
    workdir="$(pwd)"
fi

# For the terminal to be able to print Unicode characters correctly,
# the terminal charset needs to be compatible.
LC_CTYPE="en_US.UTF-8"
# Set the terminal if unset or broken
if [ -z "${TERM}" ] || [ "${TERM}" == "dumb" ]; then
    TERM="linux"
fi

# ANSI/VT100 escape sequences
esc="\x1b"
esc_normal="${esc}[0m"
esc_bold="${esc}[1m"
esc_italic="${esc}[3m"
esc_no_italic="${esc}[23m"
esc_red="${esc}[91m"

# Load paths from the .paths file
curr="${this_dir}"
while :; do
    if [ -f "${curr}/.paths" ]; then
        source "${curr}/.paths"
        break
    fi
    if [ "${curr}" == "/" ]; then
        # Print out error message and exit
        printf "${esc_bold}${esc_red}Could not find the .paths file!${esc_normal}\n" >&2
        exit 1
    fi
    curr="$(dirname "${curr}")"
done

# The time before any computation begins
start_time=$("${python}" -B -c "import time; print(time.time())")

# Function for printing colored messages
colorprint()
{
# Arguments: Message, color
"${python}" -B -c "
import sys
from blessings import Terminal
terminal = Terminal(force_styling=True)
print(terminal.bold_${2}('${1}'), file=(sys.stderr if '${2}' == 'red' else sys.stdout))"
}

# Function for printing out a nice CO𝘕CEPT logo
print_logo()
{
    logo='
   ____     ____             __  ____    _____   ____   _____  
  / __ \   / __ \     /\    / / / __ \  |  ___| |  _ \ |_   _| 
 | /  \_| | /  \ |   /  \  / / | /  \_| | |__   | |_) |  | |   
 ||    _  ||    ||  / /\ \/ /  ||    _  |  __|  |  __/   | |   
 | \__/ | | \__/ | / /  \  /   | \__/ | | |___  | |      | |   
  \____/   \____/ /_/    \/     \____/  |_____| |_|      |_|   
═══════════════════════════════════════════════════════════════
'
    # Plot the logo via Python's matplotlib.
    # This uses up the the 16th and 17th color of the terminal.
    "${python}" -B -c "
import numpy as np, matplotlib
# Apply colormap
colors = ([0.09, 0.84, 0.05], [0.98, 0.47, 0.20])
for i, color in enumerate(colors):
    colorhex = matplotlib.colors.rgb2hex(color)
    print('\\x1b]4;{};rgb:{}/{}/{}\\x1b\\\\'
           .format(16 + i, colorhex[1:3], colorhex[3:5], colorhex[5:]), end='')
# Construct the colored logo
logo='''${logo}'''
logo = logo[1:-1]
rows = logo.split('\\n')
ANSI = []
for i, row in enumerate(rows):
    for j, c in enumerate(row):
        colornumber = 17 if i < 6 and 17 < j < 31 else 16
        ANSI.append('\\x1b[38;5;{}m{}'.format(colornumber, c))
    ANSI.append('\\x1b[0m\\n')
# Print the ANSI image
print(''.join(ANSI), end='', flush=True)
     "
}
# Print out the logo the first time an execution reaches this point
if [ "${logo_printed}" != "True" ] && [ "${being_sourced}" == "False" ]; then
    print_logo
    export logo_printed="True"
fi

# Function for converting paths to absolute paths
absolute_path()
{
    # Arguments: Path, [working directory]
    local path="${1}"
    currdir="$(pwd)"
    if [ -n "${2}" ]; then
        cd "${2}"
    fi
    # Places backslashes before spaces.
    # These are needed when expanding tilde, but they will not persist.
    path="${path//[ ]/\\ }"
    # Expand tilde
    eval path="${path}"
    # Convert to absolute path
    path=$(readlink -m "${path}")
    if [ -z "${path}" ]; then
        colorprint "Cannot convert \"${1}\" to an absolute path!" "red"
        exit 1
    fi
    cd "${currdir}"
    # Print out result
    echo "${path}"
}

# Function for converting an absolute path to its "sensible" form.
# That is, this function returns the relative path with respect to the
# concept directory, if it is no more than one directory above the
# concept directory. Otherwise, return the absolute path back again.
sensible_path()
{
"${python}" -B -c "
path = '${1}'
from os.path import relpath
rel = relpath(path, '${concept_dir}')
print(path if rel.startswith('../../') else rel)"
}

# Function which prints a passed Bash array
# in the format of a Python list.
bash_array2python_list()
{
    # Call like this: bash_array2python_list array[@]
    declare -a array=("${!1}")
    local list=''
    local element
    for element in "${array[@]}"; do
        # If element is a string, encapsulate it in quotation marks
        element=$("${python}" -B -c "
try:
    eval(\"${element}\")
    print(\"${element}\")
except:
    print('\"{}\"'.format(\"${element}\"))
")
        # Append element to list
        list="$(echo "${list}")${element}, "
    done
    list="[$(echo "${list}")]"
    echo "${list}"
}

# If this file is being sourced, return now
if [ "${being_sourced}" == "True" ]; then
    this_file="${this_file_backup}"
    this_dir="${this_dir_backup}"
    return
fi

# Set up error trapping
ctrl_c()
{
    trap : 0
    exit 2
}
abort()
{
    colorprint "An error occurred!" "red"
    exit 1
}
trap 'ctrl_c' SIGINT
trap 'abort' EXIT
set -e

# Default values of command-line arguments
local_default="False"
main_default="${concept_dir}/main.py"
nowatch_default="False"
nprocs_default=1
params_default="None"
pure_python_default="False"
walltime_default=6

# Initial but illegal values of some command-line arguments,
# for testing whether these arguments have been supplied.
nprocs_unspecified="-1"
params_unspecified="__none__"
queue_unspecified="__none__"
test_unspecified="__none__"
util_unspecified="__none__"

# Change to the concept code directory
cd "${concept_dir}"

# Add the concept directory to searched paths
# when importing modules in Python.
PYTHONPATH="${concept_dir}:${PYTHONPATH}"

# On some systems, libpng finds a wrong version of the zlib shared
# library. To fix this we export the zlib library at run time.
LD_LIBRARY_PATH="${zlib_dir}/lib:${LD_LIBRARY_PATH}"

# The MPI executables and libraries should be
# on the PATH and LD_LIBRARY_PATH, respectively.
PATH="${mpi_dir}/bin:${PATH}"
LD_LIBRARY_PATH="${mpi_dir}/lib:${LD_LIBRARY_PATH}"

# Use Python's argparse module to handle command-line arguments
args=$("${python}" -B -c "
import argparse, sys
# Function which checks whether input is a
# representation of a positive integer.
def positive_int(value):
    def raise_argparse_exception():
        raise argparse.ArgumentTypeError(\"invalid positive int value: '{}'\".format(value))
    try:
        value = eval(value)
        value = float(value)
    except:
        raise_argparse_exception()
    if value != int(value):
        raise_argparse_exception()
    value = int(value)
    if value < 1:
        raise_argparse_exception()
    return value
# Setup command-line arguments
parser = argparse.ArgumentParser(prog='$(basename "${this_file}")',
                                 description='Run the CO𝘕CEPT code')
parser.add_argument('-m', '--main',
                    help=('entry point of the code. '
                          'Can be a Python filename or command.'),
                    default='${main_default}',
                    )
parser.add_argument('-n', '--nprocs',
                    help='number of processes',
                    type=positive_int,
                    default=${nprocs_unspecified},
                    )
parser.add_argument('-p', '--params',
                    help='parameterfile to use',
                    default='${params_unspecified}',
                    )
parser.add_argument('-q', '--queue',
                    help=('queue for submission of the remote job. '
                          'If omitted the script will choose a queue'
                          'with a matching number of cores/node'),
                    default='${queue_unspecified}',
                    )
parser.add_argument('-t', '--test',
                    help=('run test TEST. TEST can be any subdirectory of the tests directory. '
                          'Use TEST=all to run all tests'),
                    default='${test_unspecified}',
                    )
parser.add_argument('-u', '--util',
                    nargs='+',
                    help='run utility UTIL. UTIL can be any executable in the utilities directory',
                    default=['${util_unspecified}']*2,  # One for util, one for util_args
                    )
parser.add_argument('-w', '--walltime',
                     help='set the PBS walltime in whole hours',
                     type=positive_int,
                     default=${walltime_default},
                     )
parser.add_argument('--local',
                    help='force the run to be done locally, without submitting it via PBS',
                    default=${local_default},
                    action='store_true',
                    )
parser.add_argument('--nowatch',
                    help='do not follow the submitted job via the watch utility',
                    default=${nowatch_default},
                    action='store_true',
                    )
parser.add_argument('--pure-python',
                    help='run in pure Python mode',
                    default=${pure_python_default},
                    action='store_true',
                    )
# Enables Python to write directly to screen (stderr)
# in case of help request.
stdout_copy = sys.stdout
sys.stdout = sys.stderr
# Now do the actual argument parsing,
# including writing out the help message.
args, unknown_args = parser.parse_known_args()
# If a utility is to be used, arguments unknown to this script should
# be passed on to the utility.
util_args = args.util[1:]
if args.util[0] != '${util_unspecified}':
    util_args += unknown_args
else:
    # Do print out error if invalid arguments are given
    # and no utility should be used.
    args = parser.parse_args()
# Reset stdout
sys.stdout = stdout_copy
# Print out the arguments.
# These will be captured in the Bash 'args' variable
print(  '  argparse_finished=yes'
      + '; main=\"{}\"'.format(args.main)
      + '; nprocs={}'.format(args.nprocs)
      + '; params=\"{}\"'.format(args.params)
      + '; queue={}'.format(args.queue)
      + '; test=\"{}\"'.format(args.test)
      + '; util=\"{}\"'.format(args.util[0])
      + '; util_args=({})'.format(\"'\" + \"' '\".join(util_args) + \"'\")  # Bash array
      + '; walltime={}'.format(args.walltime)
      + '; local={}'.format(args.local)
      + '; nowatch={}'.format(args.nowatch)
      + '; pure_python={}'.format(args.pure_python)
      )
" "$@" || :)
# Evaluate the handled arguments into this scope
eval "${args}"
# Exit if argparse exited without finishing
if [ "${argparse_finished}" != "yes" ]; then
    trap : 0
    exit 0
fi

# Check whether the main "file" is really a string of commands
main_as_command="no"
if (   [[ "${main}" == *"print("* ]] \
    || [[ "${main}" == *";"*      ]] \
    || [[ "${main}" == *$'\n'*    ]]); then
    main_as_command="yes"
fi

# Convert all supplied paths to absolute paths
if [ "${main_as_command}" == "no" ]; then
    main="$(absolute_path "${main}")"
fi
if [ "${params}" != "${params_unspecified}" ]; then
    params="$(absolute_path "${params}")"
fi
if [ "${test}" != "${test_unspecified}" ] && [ "${test}" != "all" ]; then
    test="${tests_dir}/$(basename "${test}")"
fi
if [ "${util}" != "${util_unspecified}" ]; then
    util="${utilities_dir}/$(basename "${util}")"
fi

# Function for doing fuzzy comparisons between
# illegal concept options and possible correct ones.
concept_options=("$@")
suggest_correct_invocation()
{
    # First argument: The illegal option
    # Second argument: The option type ('test' or 'util')
    illegal_option="$(basename "$1")"
    invocation="$0"
    for arg in "${concept_options[@]}"; do
        if [ "${replace_next}" == "True" ]; then
            invocation="${invocation} __replace__"
            replace_next="False"
        else
            invocation="${invocation} ${arg}"
        fi
        if    ([ "$2" == "test" ] && ([ "${arg}" == "-t" ] || [ "${arg}" == "--test" ])) \
           || ([ "$2" == "util" ] && ([ "${arg}" == "-u" ] || [ "${arg}" == "--util" ])); then
            replace_next="True"
        fi
    done
    "${python}" -B -c "
import difflib, shutil, os
if '$2' == 'test':
    files = os.listdir('${tests_dir}')
    possibilities = [file for file in files if os.path.isdir('${tests_dir}/' + file)]
elif '$2' == 'util':
    files = os.listdir('${utilities_dir}')
    possibilities = [file for file in files if shutil.which('${utilities_dir}/' + file)]
max_ratio = 0
for possibility in possibilities:
    ratio = difflib.SequenceMatcher(a='${illegal_option}', b=possibility).ratio()
    if ratio > max_ratio:
        max_ratio = ratio
        closest_match = possibility
if max_ratio > 0.01:
    print('Did you mean:\n${invocation}'.replace('__replace__', closest_match))
                   "
}

# Do the supplied paths exist?
if [ "${main_as_command}" == "no" ] && [ ! -f "${main}" ]; then
    colorprint "Error: Entry point \"${main}\" does not exist!" "red"
    exit 1
fi
if [ "${params}" != "${params_unspecified}" ] && [ ! -f "${params}" ]; then
    colorprint "Error: Parameterfile \"${params}\" does not exist!" "red"
    exit 1
fi
if [ "${test}" != "${test_unspecified}" ] && [ "${test}" != "all" ] && [ ! -d "${test}" ]; then
    colorprint "Error: Test \"${test}\" does not exist!" "red"
    # Suggest closest match
    suggest_correct_invocation "${test}" "test"
    exit 1
fi
if [ "${util}" != "${util_unspecified}" ] && [ ! -f "${util}" ]; then
    colorprint "Error: Utility \"${util}\" does not exist!" "red"
    # Suggest closest match
    suggest_correct_invocation "${util}" "util"
    exit 1
fi

# Assigned values to unspecified parameters
if [ "${nprocs}" == "${nprocs_unspecified}" ]; then
    nprocs="${nprocs_default}"
fi
if [ "${params}" == "${params_unspecified}" ]; then
    params="${params_default}"
fi

# If a test is to be run, run it and exit
if [ "${test}" != "${test_unspecified}" ]; then
    # Function which can extract parameters from the parameter file
    # given by "${this_dir}/params". This is used by some tests.
    get_param()
    {
        "${concept}" -n 1                                                    \
                     -p "${this_dir}/params"                                 \
                     -m "from commons import *; print('param_var =', ${1})"  \
                     --pure-python                                           \
                     --local                                                 \
                     | grep "param_var"                                      \
                     | tail -n 1                                             \
                     | sed 's/^.\{12\}//'
    }
    if [ "${test}" == "all" ]; then
        # Find and run all tests
        tests="$(cd "${tests_dir}" && "${python}" -B -c "
import glob
# List tests in order of required execution.
# Tests not included here will be run last.
order = (# Test whether the code is able to compile and run
         'basic',
         # Test of the GADGET installation
         'gadget',
         # Tests of the particle implementation
         'drift_noHubble',
         'drift',
         'kick_PP_without_Ewald',
         'kick_PP_with_Ewald',
         # Tests of the PP implementation
         'pure_python_PP',
         'concept_vs_gadget_PP',
         'nprocs_PP',
         # Tests of the PM implementation
         'pure_python_PM',
         'concept_vs_gadget_PM',
         'nprocs_PM',
         # Tests of the P³M implementation
         'pure_python_P3M',
         'concept_vs_gadget_P3M',
         'nprocs_P3M',
         # Test of the power spectrum functionality
         'powerspec',
         # Tests of the fluid implementation
         'fluid_drift_rigid_noHubble',
         'fluid_drift_rigid',
         'fluid_gravity_noHubble',
         'fluid_gravity',
         'fluid_vacuum',
         'fluid_vs_particles',
         'fluid_pressure',
         # Tests of other functionality
         'render',
         )
# Find all tests (directories in ${tests_dir}).
# Skip test if its (directory) name has a leading underscore.
tests = (dir[:-1] for dir in glob.glob('*/') if not dir.startswith('_'))
# Sort the tests based on the order given above
sorted_tests = sorted(tests, key=lambda test: order.index(test) if test in order else len(order))
for test in sorted_tests:
    print(test)
"              )"
        # Run all tests in the test directory
        echo "The following tests will be run in order:"
        for test_name in ${tests}; do
            echo "    ${test_name}"
        done
        for test_name in ${tests}; do
            start_time_test=$("${python}" -B -c "import time; print(time.time())")
            colorprint "\nRunning ${test_name} test" "yellow"
            "${tests_dir}/${test_name}/run_test"
            colorprint "${test_name} test ran successfully" "green"
            # Print out the execution time for this test
            "${python}" -B -c "from commons import *; print('Total execution time: {}'.format(time_since(${start_time_test})))"
        done
        colorprint "\nAll tests ran successfully" "green"
    else
        # Run specific test
        test_name="$(basename "${test}")"
        colorprint "Running ${test_name} test" "yellow"
        "${test}/run_test"
        colorprint "${test_name} test ran successfully" "green"
    fi
    # Print out the total time it took to ran the test(s)
    "${python}" -B -c "from commons import *; print('Total execution time: {}'.format(time_since(${start_time})))"
    # Deactivate traps and exit
    trap : 0
    exit 0
fi

# Check whether this script is run locally or remotely via ssh
ssh="True"
if [ -z "${SSH_CLIENT}" ] && [ -z "${SSH_TTY}" ]; then
    ssh="False"  
fi

# Determine the MPI implentations used
if [ -f "${mpi_dir}/bin/ompi_info" ]; then
    mpi_implementation="openmpi"
elif [ -f "${mpi_dir}/bin/mpichversion" ]; then
    mpi_implementation="mpich"
else
    mpi_implementation="unknown"
fi

# MPI implementation specifics
if [ "${mpi_implementation}" == "openmpi" ]; then
    # Extra arguments to pass to mpiexec
    mpiexec_args=""
    # If OpenMPI complains about openib, it may be having problems
    # with infiniband. Try adding "-mca btl ^openib" to mpiexec_args.
    # Note that --prefix should not be used,
    # as the absolute path to mpiexec is given.
    # MPI preparations (Bash code)
    mpi_preparations="# Disable aggregation of OpenMPI warnings
                      export OMPI_MCA_orte_base_help_aggregate=0
                      # Disable OpenMPI warning about forking
                      export OMPI_MCA_mpi_warn_on_fork=0
                      "
elif [ "${mpi_implementation}" == "mpich" ]; then
    # Extra arguments to pass to mpiexec
    mpiexec_args=""
    # MPI preparations (bash code)
    mpi_preparations=""
fi
eval "${mpi_preparations}"

# Compile or do cleanup from last compilation.
# The only time where neither should be done
# is when running some particular utilities.
prepare_files="True"
if    [ "$(basename "${util}")" == "play"   ] \
   || [ "$(basename "${util}")" == "update" ] \
   || [ "$(basename "${util}")" == "watch"  ]; then
   prepare_files="False"
fi
if [ "${prepare_files}" == "True" ]; then
    if [ "${pure_python}" == "True" ]; then
        # Rename compiled Cython modules *.so to *.so_
        if ls "${concept_dir}/"*.so > /dev/null 2>&1; then
            (cd "${concept_dir}" && for f in *.so; do
                                        mv "${f}" "${f%.so}.so_"
                                    done
             )
        fi
    else
        # Rename compiled Cython modules *.so_ back to *.so
        # and compile with Cython.
        if ls "${concept_dir}/"*.so_ > /dev/null 2>&1; then
            (cd "${concept_dir}" && for f in *.so_; do
                                        mv "${f}" "${f%.so_}.so"
                                    done
             )
        fi
        # Compile all the modules. If working locally, do it in parallel.
        if [ "${ssh}" == "True" ]; then
            (cd "${concept_dir}" && make)
        else
            (cd "${concept_dir}" && make -j)
        fi
    fi
fi

# Determine wheter to run CO𝘕CEPT locally or remotely (via PBS).
# Always treat tests as if they were run locally.
remote="False"
if [ "${local}" == "False" ] && [ "${test}" == "${test_unspecified}" ] \
                             && [ "${ssh}" == "True" ]; then
    remote="True"
fi

# If a utility is to be run, run it and exit
if [ "${util}" != "${util_unspecified}" ]; then
    # If no argument was passed after the -u option,
    # util_args should be empty.
    if [ "${util_args}" == '""' ] || [ "${util_args}" == "''" ]; then
        util_args=""
    fi
    # Set flag variables for the flag command options,
    # so that a utility can call this script with the same flags enabled
    # as what used to invoke this script originally.
    local_flag=""
    if [ "${local}" == "True" ]; then
        local_flag="--local"
    fi
    nowatch_flag=""
    if [ "${nowatch}" == "True" ]; then
        nowatch_flag="--nowatch"
    fi
    pure_python_flag=""
    if [ "${pure_python}" == "True" ]; then
        pure_python_flag="--pure-python"
    fi
    # Run utility util and exit
    colorprint "Running the $(basename "${util}") utility" "yellow"
    trap : 0
    if [ -z "${util_args[0]}" ] && [ ${#util_args[@]} == 1 ]; then
        called_from_concept="True" "${util}"
    else
        called_from_concept="True" "${util}" "${util_args[@]}"
    fi
    # Print out the total execution time for this utility
    "${python}" -B -c "from commons import *; print('Total execution time: {}'.format(time_since(${start_time})))"
    exit 0
fi

# Sensible paths (for clean printout)
if [ "${main_as_command}" == "no" ]; then
    main_rel="$(sensible_path ${main})"
else
    main_rel="${main}"
fi
params_rel="$(sensible_path ${params})"
logs_dir_rel="$(sensible_path ${logs_dir})"

# Create the logs dir if it does not exist
mkdir -p "${logs_dir}"

# Either stop doing further actions, submit job or run it locally
if [ ${#queues[@]} == 0 ] && [ "${remote}" == "True" ]; then
    # This script was invoked remotely but no queues are known.
    # Do not submit the job.
    printf "\nThe CO𝘕CEPT code is ready to be submitted.\n\
Automatic PBS submition can be enabled by specifying one or more queue names and the \
corresponding number of cores/node in the \"queues\" and \"ppns\" arrays in the concept script.\n\
Alternatively, supply the --local flag when invoking the concept script to run the code directly, \
without submitting it as a PBS job.\n\n"
    trap : 0
    exit 0
elif [ ${#queues[@]} -gt 0 ] && [ "${remote}" == "True" ]; then
    # Run remotely.
    # If no queue is explicitly chosen, find a queue for
    # which the job can utilize all CPUs on the nodes
    if [ "${queue}" == "${queue_unspecified}" ]; then
        for ((i = 0; i < ${#queues[@]}; i += 1)); do
            queue="${queues[i]}"
            ppn="${ppns[i]}"
            if [ $((${nprocs} % ${ppn})) == 0 ]; then
                break
            fi
        done
        if [ $((${nprocs} % ${ppn})) != 0 ]; then
            colorprint "Error: Job submission refused: The number of processes (${nprocs}) is not \
divisible by the number of cores per node in any queue" "red"
            exit 1
        fi
        nodes="$((${nprocs} / ${ppn}))"
    else
        # How many CPUs does the explicitly chosen queue have per node?
        ppn="None"
        for ((i = 0; i < ${#queues[@]}; i += 1)); do
            if [ "${queue}" == "${queues[${i}]}" ]; then
                ppn="${ppns[${i}]}"
                break
            fi
        done
        if [ "${ppn}" == "None" ] || [ -z "${ppn}" ] ; then
            colorprint "Error: The requested queue \"${queue}\" is not familiar to me." "red"
            colorprint "Please specify it in the \"queues\" and \"ppns\" variables." "red"
            exit 1
        fi
        nodes=$((${nprocs} / ${ppn}))
        # Check that the explicitly chosen queue can be run
        # with all the node's CPUs in use.
        if [ $((${nprocs} % ${ppn})) != 0 ]; then
            colorprint "Warning: The number of processes (${nprocs}) is not divisible by \
the number of cores per node (${ppn}) in queue ${queue}" "red"
            read -p "Submit anyway? [y/N] " yn
            case "${yn}" in
                [Yy]* ) ;;
                [Nn]* ) echo "Job submission refused"; trap : 0; exit 0;;
                ""    ) echo "Job submission refused"; trap : 0; exit 0;;
                *     ) echo "Job submission refused"; trap : 0; exit 0;;
            esac
            # Not every CPU pr. node should be used.
            # Find the right number.
            while [ ${ppn} -gt 1 ]; do
                ((ppn -= 1))
                if [ $((${nprocs} % ${ppn})) == 0 ]; then
                    nodes=$((${nprocs} / ${ppn}))
                    break
                fi
            done
        fi
    fi
    # Write a jobscript file
    printf "#!/usr/bin/env bash
#PBS -N CONCEPT:${params_rel}:CONCEPT
#PBS -q ${queue}
#PBS -l nodes=${nodes}:ppn=${ppn}
#PBS -l walltime=${walltime}:00:00
#PBS -o /dev/null
#PBS -e /dev/null

# Change to the logs directory, so that autogenerated files will be dumped there
cd \"${logs_dir}\"

# Get the ID of the current job
jobid=\"\${PBS_JOBID%%.*}\"

# For the terminal to be able to print Unicode characters correctly,
# the terminal charset needs to be compatible.
export LC_CTYPE=\"en_US.UTF-8\"
# Set the terminal if unset or broken
if [ -z \"\${TERM}\" ] || [ \"\${TERM}\" == \"dumb\" ]; then
    export TERM=\"linux\"
fi

# Do MPI preparations, if any
${mpi_preparations}

# Set and export path environment variables
export PATH=\"${PATH}:\${PATH}\"
export LD_LIBRARY_PATH=\"${LD_LIBRARY_PATH}:\${LD_LIBRARY_PATH}\"

# Source the concept script
source \"${concept}\"

# Print start messages
if [ \"${pure_python}\" == \"True\" ]; then
    colorprint \"Running CO𝘕CEPT job \${jobid} in pure Python mode remotely on \$(hostname -f)\" \
               \"yellow\" > \"${logs_dir}/\${jobid}\"
else
    colorprint \"Running CO𝘕CEPT job \${jobid} remotely on \$(hostname -f)\" \
               \"yellow\" > \"${logs_dir}/\${jobid}\"
fi
echo \"Entry point:   \\\\\"${main_rel}\\\\\"\"               >> \"${logs_dir}/\${jobid}\"
if [ \"${params_rel}\" == \"None\" ]; then
    echo \"Parameterfile: ${params_rel}\"                     >> \"${logs_dir}/\${jobid}\"
else
    echo \"Parameterfile: \\\\\"${params_rel}\\\\\"\"         >> \"${logs_dir}/\${jobid}\"
fi
echo \"Logfile:       \\\\\"${logs_dir_rel}/\${jobid}\\\\\"\" >> \"${logs_dir}/\${jobid}\"
echo \"Nr. of CPUs:   ${nprocs}\"                             >> \"${logs_dir}/\${jobid}\"

# Prepare Python options
if [ \"${main_as_command}\" == \"yes\" ]; then
    # Run main as Python command
    main_as_library=\"${main}\"
    m_flag=\"-c\"
else
    if [ \"${pure_python}\" == \"True\" ]; then
        # Run main as normal Python script
        main_as_library=\"${main}\"
        m_flag=\"\"
    else
        main_as_library=\"${main%.*}.so\"
        if [ -f \"\${main_as_library}\" ]; then
            # Run main as compiled library module
            main_as_library=\"\$(basename \"\${main_as_library}\")\"
            m_flag=\"-m\"
        else
            # Run main as normal Python script,
            # even though the CO𝘕CEPT modules are compiled.
            main_as_library=\"${main}\"
            m_flag=\"\"
        fi
    fi
fi

# Run the code. Both stdout and stderr are being logged to logs_dir/jobid,
# while the stderr alone is also logged to logs_dir/jobid_err.
(cd \"${concept_dir}\" && \"${mpiexec}\" ${mpiexec_args}                                  \
                                         \"${python}\" -B                                 \
                                                       \${m_flag} \"\${main_as_library}\" \
                                                       \"params='${params}'\"             \
                                                       \"jobid='\${jobid}'\"              \
 >> \"${logs_dir}/\${jobid}\" 2>> >(tee -a \"${logs_dir}/\${jobid}_err\"))

# Run complete. Remove error log if empty
if [ -f \"${logs_dir}/\${jobid}_err\" ] && [ ! -s \"${logs_dir}/\${jobid}_err\" ]; then
    rm \"${logs_dir}/\${jobid}_err\"
else
    colorprint \"\\\nSome warnings/errors occured during CO𝘕CEPT run!\" \"red\" \
               >> \"${logs_dir}/\${jobid}\" 2>&1
    colorprint \"Check the following error log for more information:\"  \"red\" \
               >> \"${logs_dir}/\${jobid}\" 2>&1
    colorprint \"\\\\\"${logs_dir}/\${jobid}_err\\\\\"\"                \"red\" \
               >> \"${logs_dir}/\${jobid}\" 2>&1
fi
" > "${this_dir}/jobscript"
    # Check for the qsub command
    qsub_path="$(which qsub 2> /dev/null || :)"
    if [ -z "${qsub_path}" ]; then
        colorprint "Error: Could not find the \'qsub\' command. \
Is PBS installed and on the PATH?" "red"
        exit 1
    fi
    # Submit the remote job from within the logs directory,
    # so that autogenerated files will be dumped there.
    jobid=$(cd "${logs_dir}" && qsub "${this_dir}/jobscript")
    jobid="${jobid%.*}"
    colorprint "\nSubmitting job" "yellow"
    echo "Job ${jobid} (parameterfile \"${params_rel}\") submitted to queue ${queue}"
    # Deactivate traps before exiting
    trap : 0
    if [ "${nowatch}" == "False" ]; then
        echo "You can now kill (Ctrl-C) this script without cancelling the job"
    fi
    sleep 1
    # Invoke the watch utility on the submitted job
    # unless --nowatch was supplied.
    if [ "${nowatch}" == "False" ]; then
        "${concept}" --util watch "${jobid}"
    fi
    exit 0
else
    # Run locally.
    # Construct a jobid that does not conflict
    # with the content of the logs dir.
    jobid=0
    while :; do
        if [ ! -f "${logs_dir}/${jobid}" ]; then
            break
        fi
        ((jobid += 1))
    done
    # Print start message
    echo
    if [ "${pure_python}" == "True" ]; then
        colorprint "Running CO𝘕CEPT in pure Python mode" "yellow" | tee    "${logs_dir}/${jobid}"
    else
        colorprint "Running CO𝘕CEPT" "yellow"                     | tee    "${logs_dir}/${jobid}"
    fi
    echo "Entry point:   \"${main_rel}\""                         | tee -a "${logs_dir}/${jobid}"
    if [ "${params_rel}" == "None" ]; then
        echo "Parameterfile: ${params_rel}"                       | tee -a "${logs_dir}/${jobid}"
    else
        echo "Parameterfile: \"${params_rel}\""                   | tee -a "${logs_dir}/${jobid}"
    fi
    echo "Logfile:       \"${logs_dir_rel}/${jobid}\""            | tee -a "${logs_dir}/${jobid}"
    echo "Nr. of CPUs:   ${nprocs}"                               | tee -a "${logs_dir}/${jobid}"
    # Prepare Python options
    if [ "${main_as_command}" == "yes" ]; then
        # Run main as Python command
        main_as_library="${main}"
        m_flag="-c"
    else
        if [ "${pure_python}" == "True" ]; then
            # Run mail as normal Python script
            main_as_library="${main}"
            m_flag=""
        else
            main_as_library="${main%.*}.so"
            if [ -f "${main_as_library}" ]; then
                # Run main as compiled library module
                main_as_library="$(basename "${main_as_library}")"
                m_flag="-m"
            else
                # Run main as normal Python script,
                # even though the CO𝘕CEPT modules are compiled.
                main_as_library="${main}"
                m_flag=""
            fi
        fi
    fi
    # Run the code. Print stdout and stderr to the terminal while at the
    # same time logging them to logs_dir/jobid. The stderr alone is also
    # logged to logs_dir/jobid_err.
    (("${mpiexec}" -n "${nprocs}"                               \
                   ${mpiexec_args}                              \
                   "${python}" -B                               \
                               ${m_flag} "${main_as_library}"   \
                               "params='${params}'"             \
                               "jobid='${jobid}'"               \
     | tee -a "${logs_dir}/${jobid}";                           \
       echo "${PIPESTATUS[0]}" > "${this_dir}/.exit_code"       \
     ) 3>&1 1>&2 2>&3 | tee -a "${logs_dir}/${jobid}"           \
                               "${logs_dir}/${jobid}_err") 3>&1 1>&2 2>&3
    sleep 1
    concept_exit_code="$(cat "${this_dir}/.exit_code")"
    # Cleanup
    rm -f "${this_dir}/.exit_code"
    # Run complete. Remove error log if empty
    if [ -f "${logs_dir}/${jobid}_err" ] && [ ! -s "${logs_dir}/${jobid}_err" ]; then
        rm "${logs_dir}/${jobid}_err"
    else
        colorprint "\nSome warnings/errors occured during CO𝘕CEPT run!\n\
Check the following error log for more information:\n\
\"${logs_dir}/${jobid}_err\"" "red" 2>&1 | tee -a "${logs_dir}/${jobid}" 1>&2
    fi
    # If the CO𝘕CEPT run exited erroneously, exit now
    if [ "${concept_exit_code}" != "0" ]; then
        exit 1
    fi
    # Deactivate traps and exit
    trap : 0
    exit 0
fi
