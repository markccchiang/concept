#!/usr/bin/env bash

# This file is part of CO𝘕CEPT, the cosmological 𝘕-body code in Python.
# Copyright © 2015 Jeppe Mosgaard Dakin.
#
# CO𝘕CEPT is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# CO𝘕CEPT is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with CO𝘕CEPT. If not, see http://www.gnu.org/licenses/
#
# The auther of CO𝘕CEPT can be contacted at
# jeppe.mosgaard.dakin(at)post.au.dk
# The latest version of CO𝘕CEPT is available at
# https://github.com/jmd-dk/concept/



# This script runs the CO𝘕CEPT code.
# Run the script with the -h option to get help.

# If this file is being sourced, backups of 'this_file' and 'this_dir'
# is needed not to alter the values of these variables.
this_file_backup="${this_file}"
this_dir_backup="${this_dir}"

# Absolute paths to this file and its directory
this_file="$(readlink -f "${BASH_SOURCE[0]}")"
this_dir="$(dirname "${this_file}")"

# ANSI/VT100 escape sequences
esc="\x1b"
esc_normal="${esc}[0m"
esc_bold="${esc}[1m"
esc_italic="${esc}[3m"
esc_no_italic="${esc}[23m"
esc_red="${esc}[91m"

# Load paths from the .paths file
curr="${this_dir}"
while :; do
    if [ -f "${curr}/.paths" ]; then
        source "${curr}/.paths"
        break
    fi
    if [ "${curr}" == "/" ]; then
        # Print out error message and exit
        printf "${esc_bold}${esc_red}Could not find the .paths file!${esc_normal}\n" >&2
        exit 1
    fi
    curr="$(dirname "${curr}")"
done

# Function for printing colored messages
terminal_CONCEPT="CO${esc_italic}N${esc_no_italic}CEPT"
colorprint()
{
# Arguments: Message, color
"${python}" -B -c "
import sys
from blessings import Terminal
terminal = Terminal(force_styling=True)
msg='${1}'.replace('CONCEPT', '${terminal_CONCEPT}')
print(terminal.bold_${2}(msg), file=(sys.stderr if '${2}' == 'red' else sys.stdout))"
}

# Function for converting paths to absolute paths
absolute()
{
    local path="${1}"
    local path_backup="${path}"
    path="${path//[ ]/\\ }"        # Places backslashes before spaces. These are needed when expanding tilde, but they will not persist!
    eval path="${path}"            # Expand tilde
    path=$(readlink -m "${path}")  # Convert to absolute path
    if [ -z "${path}" ]; then
        colorprint "Cannot convert \"${path_backup}\" to an absolute path!" "red"
        exit 1
    fi
    echo "${path}"
} 

# If this file is being sourced, return now
if [ "${BASH_SOURCE[0]}" != "${0}" ]; then
    this_file="${this_file_backup}"
    this_dir="${this_dir_backup}"
    return
fi

# Default values of command-line arguments
local_default="False"
main_default="${concept_dir}/main.py"
nprocs_default=1
params_default="None"
pure_python_default="False"
walltime_default=72
# List of remote queues and number of CPUs per node. The first queue is the default queue 
queues=(q8n q8 q4)
ppns=(8 8 4)
# Should PBS be used to submit remote jobs?
use_PBS="True"

# Initial but illegal values of some command-line arguments,
# for testing whether these arguments have been supplied.
nprocs_unspecified="-1"
params_unspecified="__none__"
queue_unspecified="__none__"
test_unspecified="__none__"
util_unspecified="__none__"

# Change to the concept code directory
cd "${concept_dir}"

# On some systems, libpng finds a wrong version of the zlib shared
# library. To fix this we export the zlib library at run time.
export LD_LIBRARY_PATH="${zlib_dir}/lib:${LD_LIBRARY_PATH}"
# For the terminal to be able to print Unicode characters correctly,
# the terminal charset need to be compatible.
export LC_CTYPE="en_US.UTF-8"
# Set the terminal if unset or broken
if [ -z "${TERM}" ] || [ "${TERM}" == "dumb" ]; then
    export TERM="linux"
fi

# Use Python's argparse module to handle command-line arguments
args=($("${python}" -B -c "
import argparse, sys
# Setup command-line arguments
def positive_int(value):
    def raise_argparse_exception():
        raise argparse.ArgumentTypeError(\"invalid positive int value: '{}'\".format(value))
    try:
        value = eval(value)
        value = float(value)
    except:
        raise_argparse_exception()
    if value != int(value):
        raise_argparse_exception()
    value = int(value)
    if value < 1:
        raise_argparse_exception()
    return value
parser = argparse.ArgumentParser(prog='$(basename ${this_file})',
                                 description='Run the CONCEPT code')
parser.add_argument('-m', '--main',
                    help='entry point of the code',
                    default='${main_default}',
                    )
parser.add_argument('-n', '--nprocs',
                    help='number of processes',
                    type=positive_int,
                    default=${nprocs_unspecified},
                    )
parser.add_argument('-p', '--params',
                    help='parameterfile to use',
                    default='${params_unspecified}',
                    )
parser.add_argument('-q', '--queue',
                    help='queue for submission of the remote job. If omitted the script will try to choose the best.',
                    default='${queue_unspecified}',
                    )
parser.add_argument('-t', '--test',
                    help='run test TEST. TEST can be any subdirectory of the tests directory. Use TEST=all to run all tests',
                    default='${test_unspecified}',
                    )
parser.add_argument('-u', '--util',
                    nargs='+',
                    help='run utility UTIL. UTIL can be any executable in the utilities directory',
                    default=['${util_unspecified}'],
                    )
parser.add_argument('-w', '--walltime',
                     help='set the PBS walltime in whole hours',
                     type=positive_int,
                     default=${walltime_default},
                     )
parser.add_argument('--local',
                    help='force the run to be done locally, without submitting it via PBS',
                    default=${local_default},
                    action='store_true',
                    )
parser.add_argument('--pure-python',
                    help='run in pure Python mode',
                    default=${pure_python_default},
                    action='store_true',
                    )
# Enables Python to write directly to screen (stderr)
# in case of help request
stdout_copy = sys.stdout
sys.stdout = sys.stderr
# Now do the actual argument parsing, including writing out the help message
args = parser.parse_args()
# Reset stdout
sys.stdout = stdout_copy
# Print out the arguments.
# These will be captured in the bash 'args' variable
print('graceful_exit',
      args.main,
      args.nprocs,
      args.params,
      args.queue,
      args.test,
      args.util[0],
      '\"' + '\"__space__\"'.join(args.util[1:]).replace(' ','__space__') + '\"' if len(args.util) > 1 else '\"\"',
      args.walltime,
      args.local,
      args.pure_python,
      )
" "$@"))
graceful_exit="${args[0]}"
main="${args[1]}"
nprocs="${args[2]}"
params="${args[3]}"
queue="${args[4]}"
test="${args[5]}"
util="${args[6]}"
util_args="${args[7]//__space__/ }"
walltime="${args[8]}"
local="${args[9]}"
pure_python="${args[10]}"
if [ -z "${graceful_exit}" ]; then
    # Help requested and given. Exit
    trap : 0
    exit 0
fi
if [ "${#args[@]}" -ne 11 ]; then
    colorprint "Error: Not every command-line argument was gracefully dealt with!" "red"
    exit 1
fi

# Set up error trapping
ctrl_c()
{
    trap : 0
    exit 2
}
abort()
{
    colorprint "An error occurred!" "red"
    exit 1
}
trap 'ctrl_c' SIGINT
trap 'abort' EXIT
set -e

# Convert all supplied paths to absolute paths
main="$(absolute "${main}")"
if [ "${params}" != "${params_unspecified}" ]; then
    params="$(absolute "${params}")"
fi
if [ "${test}" != "${test_unspecified}" ] && [ "${test}" != "all" ]; then
    test="${tests_dir}/$(basename "${test}")"
fi
if [ "${util}" != "${util_unspecified}" ]; then
    util="${utilities_dir}/$(basename "${util}")"
fi

# Do the supplied paths exist?
if [ ! -f "${main}" ]; then
    colorprint "Error: Entry point \"${main}\" does not exist!" "red"
    exit 1
fi
if [ "${params}" != "${params_unspecified}" ] && [ ! -f "${params}" ]; then
    colorprint "Error: Parameterfile \"${params}\" does not exist!" "red"
    exit 1
fi
if [ "${test}" != "${test_unspecified}" ] && [ "${test}" != "all" ] && [ ! -d "${test}" ]; then
    colorprint "Error: Test \"${test}\" does not exist!" "red"
    exit 1
fi
if [ "${util}" != "${util_unspecified}" ] && [ ! -f "${util}" ]; then
    colorprint "Error: Utility \"${util}\" does not exist!" "red"
    exit 1
fi

# Assigned values to unspecified parameters
running_test_or_util="False"
if [ "${util}" != "${util_unspecified}" ] || [ "${test}" != "${test_unspecified}" ]; then
    running_test_or_util="True"
fi
if [ "${nprocs}" == "${nprocs_unspecified}" ]; then
    nprocs="${nprocs_default}"
    if [ "${running_test_or_util}" == "False" ]; then
        echo "Number of processes not specified - Will use ${nprocs}"
    fi
fi
if [ "${params}" == "${params_unspecified}" ]; then
    params="${params_default}"
    if [ "${running_test_or_util}" == "False" ]; then
        echo "Parameterfile not specified - Will use default parameters"
    fi
fi

# If a test is to be run, run it and exit
if [ "${test}" != "${test_unspecified}" ]; then
    if [ "${test}" == "all" ]; then
        trap : 0
        for dir in "${tests_dir}/"*/; do
            dir=${dir%*/}
            colorprint "\nRunning $(basename ${dir}) test" "yellow"
            "${dir}/run_test"
        done
        colorprint "All tests ran successfully" "green"
    else
        colorprint "Running $(basename ${test}) test" "yellow"
        trap : 0
        "${test}/run_test"
    fi
    exit 0
fi

# If a utility is to be run, run it and exit
if [ "${util}" != "${util_unspecified}" ]; then
    # Export every command-line argument. These will be fed back into
    # this script when called from the utility.
    export main="${main}"
    export nprocs="${nprocs}"
    export params="${params}"
    export queue="${queue}"
    export test="${test}"
    export util="${util}"
    export walltime="${walltime}"
    local_flag=""
    if [ "${local}" == "True" ]; then
        local_flag="--local"
    fi
    export local_flag="${local_flag}"
    pure_python_flag=""
    if [ "${pure_python}" == "True" ]; then
        pure_python_flag="--pure-python"
    fi
    export pure_python_flag="${pure_python_flag}"
    colorprint "Running the $(basename ${util}) utility" "yellow"
    trap : 0
    eval called_from_concept=True "${util}" ${util_args}
    exit 0
fi

# Sensible paths to the main and parameter file, for clean printout
main_rel=$(${python}   -B -c "from os.path import relpath; rel = relpath('${main}',   '${concept_dir}'); print(rel if not rel.startswith('../../') else '${main}')")
params_rel=$(${python} -B -c "from os.path import relpath; rel = relpath('${params}', '${concept_dir}'); print(rel if not rel.startswith('../../') else '${params}')")

# Prompt the user for the secure shell password,
# if the live render should be uploaded to a remote host.
args=($("${python}" -B -c "
import os, pexpect, re, sys
from getpass import getpass
from time import sleep
# Import parameters from the commons module
from commons import *
# Ask for password if remote liverender is requested
scp_password = ''
scp_success = 'success'
if remote_liverender:
    # Create test file to be scp'ed
    test_filename = '${this_dir}/.scp_test'
    with open(test_filename, 'a'):
        pass
    # Spawn the interactive process
    cmd = 'scp \"{}\" \"{}\"'.format(test_filename, remote_liverender)
    scp_host = re.search('@(.*):', remote_liverender).group(1)
    scp_dist = re.search(':(.*)',  remote_liverender).group(1)
    expects = ['password.*',
               'passphrase.*',
               'continue connecting',
               pexpect.EOF,
               pexpect.TIMEOUT,
               ]
    print('\nThe latest render will continuously be scp\'ed to\n\"{}\" at {}'
           .format(scp_dist, scp_host), file=sys.stderr)
    child = pexpect.spawn(cmd, timeout=15, env={'SSH_ASKPASS': '',
                                                'DISPLAY'    : ''})
    # Interactions
    while True:
        n = child.expect(expects)
        if n < 2:
            # scp asks for password or passphrase. Prompt the user for it
            scp_password = getpass((child.before + child.after).decode('utf-8'))
            # Now supply scp with the password
            child.sendline(scp_password)
        elif n == 2:
            # scp cannot authenticate host. Connect anyway
            child.sendline('yes')
        elif n == 3:
            # 
            break
        else:
            child.kill(9)
            break
    child.close(force=True)
    os.remove(test_filename)
    # If the test scp did not go well, reset password and write error message
    if child.status:
        scp_password = ''
        scp_success = ('Warning: Could not establish connection to {}\\\n'
                       + \"Remote live renders will not be scp\\\'ed\"
                       ).format(scp_host)
# Print out the password/passphrase and whether the scp test was
# successful. These will be captured in the bash 'args' variable.
print(scp_success.replace(' ', '~'),
      scp_password,
      )
" "params='${params}'"))
scp_success="${args[0]//\~/ }"
scp_password="${args[1]}"
if [ "${scp_success}" != "success" ]; then
    colorprint "${scp_success}" "red"
    sleep 10
fi

# Compile or do cleanup from last compilation
if [ "${pure_python}" == "True" ] ; then
    # Rename compiled Cython modules *.so to *.so_
    if ls "${concept_dir}/"*.so > /dev/null 2>&1; then
        (cd "${concept_dir}" && for f in *.so; do mv "${f}" "${f%.so}.so_"; done)
    fi
else
    # Rename compiled Cython modules *.so_ back to *.so and compile with Cython
    if ls "${concept_dir}/"*.so_ > /dev/null 2>&1; then
        (cd "${concept_dir}" && for f in *.so_; do mv "${f}" "${f%.so_}.so"; done)
    fi
    (cd "${concept_dir}" && make)
fi

# Create the logs dir if it does not exist
mkdir -p "${logs_dir}"

# Determine whether this script is run locally or remotely via ssh.
# Always treat tests as if they were run locally.
remote="False"
if [ "${local}" == "False" ] && [ "${test}" == "${test_unspecified}" ] && ([ -n "${SSH_CLIENT}" ] || [ -n "${SSH_TTY}" ]); then
    remote="True"
fi

# Either stop doing further actions, submit job or run it locally
if [ "${use_PBS}" != "True" ] && [ "${remote}" == "True" ]; then
    # Run remotely but do not use PBS
    printf "The ${terminal_CONCEPT} code is ready to be submitted"
    trap : 0
elif [ "${use_PBS}" == "True" ] && [ "${remote}" == "True" ]; then
    # Run remotely.
    # If no queue is explicitly chosen, use one with enough free nodes
    if [ "${queue}" == "${queue_unspecified}" ]; then
        # The first queue in the list is the default queue
        queue="${queues[0]}"
        ppn="${ppns[0]}"
        # Change to the queue that has enough free CPUS to begin job immediately
        node_table=$(nodes)
        for i in $(eval echo "{0..${#queues[@]}}" | sed s/'\w*$'//); do
            free_nodes=$(echo "${node_table}" | grep -o -P "(?<= ${queues[${i}]}:).*(?= free)" | awk '{print $NF}')
            free_cpus=$(echo "$((${free_nodes} * ${ppns[${i}]}))")
            if [ "${free_cpus}" -ge "${nprocs}" ] && [ "$((${nprocs} % ${ppns[${i}]}))" -eq 0 ]; then
                queue="${queues[${i}]}"
                ppn="${ppns[${i}]}"
                break
            fi
        done
        # Check that the chosen queue can be run with all the node's CPUs in use
        if [ $((${nprocs} % ${ppn})) != 0 ]; then
            colorprint "Error: Job submission refused: The number of processes (${nprocs}) is not divisible by the number of cores per node in any queue" "red"
            exit 1
        fi
        nodes="$((${nprocs} / ${ppn}))"
    else
        # How many CPUs does the explicitly chosen queue have per node?
        for i in $(eval echo "{0..${#queues[@]}}" | sed s/'\w*$'//); do
            if [ "${queue}" == "${queues[${i}]}" ]; then
                ppn="${ppns[${i}]}"
                break
            fi
        done
        nodes=$((${nprocs} / ${ppn}))
        # Check that the explicitly chosen queue can be run with all the node's CPUs in use
        if [ $((${nprocs} % ${ppn})) != 0 ]; then
            colorprint "Warning: The number of processes (${nprocs}) is not divisible by the number of cores per node (${ppn}) in queue ${queue}" "red"
            read -p "Submit anyway? [y/N] " yn
            case "${yn}" in
                [Yy]* ) ;;
                [Nn]* ) echo "Job submission refused"; trap : 0; exit 0;;
                ""    ) echo "Job submission refused"; trap : 0; exit 0;;
                *     ) echo "Job submission refused"; trap : 0; exit 0;;
            esac
            # Not every CPU pr. node should be used. Find the right number
            while [ ${ppn} -gt 1 ]; do
                ((ppn -= 1))
                if [ $((${nprocs} % ${ppn})) == 0 ]; then
                    nodes=$((${nprocs} / ${ppn}))
                    break
                fi
            done
        fi
    fi
    # Write a jobscript file
    printf "#!/usr/bin/env bash
#PBS -N $(whoami):CONCEPT:$(basename ${params})
#PBS -q ${queue}
#PBS -l nodes=${nodes}:ppn=${ppn}
#PBS -l walltime=${walltime}:00:00
#PBS -o /dev/null
#PBS -e /dev/null

# Change to the logs directory, so that autogenerated files will be dumped there
cd \"${logs_dir}\"

# Get the id of the current job
jobid=\"\${PBS_JOBID%%.in1}\"

# Set and export path environment variables
export PATH=\"${PATH}:\${PATH}\"
export LD_LIBRARY_PATH=\"${LD_LIBRARY_PATH}:\${LD_LIBRARY_PATH}\"

# On some systems, libpng finds a wrong version of the zlib shared
# library. To fix this we export the zlib library at run time.
export LD_LIBRARY_PATH=\"${zlib_dir}/lib:\${LD_LIBRARY_PATH}\"
# For the terminal to be able to print Unicode characters correctly,
# the terminal charset need to be compatible.
export LC_CTYPE=\"en_US.UTF-8\"
# Set the terminal if unset or broken
if [ -z \"\${TERM}\" ] || [ \"\${TERM}\" == \"dumb\" ]; then
    export TERM=\"linux\"
fi

# Source the concept script
source \"${concept}\"

# Print start messages
if [ \"${pure_python}\" == \"True\" ]; then
    colorprint \"Running CONCEPT in pure Python mode remotely on \$(hostname -f) as job \${jobid}\" \"yellow\" > \"${logs_dir}/\${jobid}\"
else
    colorprint \"Running CONCEPT remotely on \$(hostname -f) as job \${jobid}\" \"yellow\" > \"${logs_dir}/\${jobid}\"
fi
echo \"Entry point:   \\\\\"${main_rel}\\\\\"\"           >> \"${logs_dir}/\${jobid}\"
echo \"Parameterfile: \\\\\"${params_rel}\\\\\"\"         >> \"${logs_dir}/\${jobid}\"
echo \"Logfile:       \\\\\"${logs_dir}/\${jobid}\\\\\"\" >> \"${logs_dir}/\${jobid}\"
echo \"Nr. of CPUs:   ${nprocs}\"                         >> \"${logs_dir}/\${jobid}\"

# Prepare Python options
if [ \"${pure_python}\" == \"True\" ]; then
    # Run as normal Python script
    main_as_library=\"${main}\"
    m_flag=\"\"
else
    # Run as compiled library module
    main_as_library=\"$(basename "${main%.*}.so")\"
    m_flag=\"-m\"
fi

# Run the code. Both stdout and stderr are being logged to logs_dir/jobid,
# while the stderr alone is also logged to logs_dir/jobid_err.
(cd \"${concept_dir}\" && \"${mpiexec}\" \"${python}\" -B \${m_flag} \"\${main_as_library}\" \"params='${params}'\" \"scp_password='${scp_password}'\" >> \"${logs_dir}/\${jobid}\" 2>> >(tee -a \"${logs_dir}/\${jobid}_err\"))

# Run complete. Remove error log if empty
if [ -f \"${logs_dir}/\${jobid}_err\" ] && [ ! -s \"${logs_dir}/\${jobid}_err\" ]; then
    rm \"${logs_dir}/\${jobid}_err\"
else
    colorprint \"\\\nSome warnings/errors occured during CONCEPT run!\" \"red\" >> \"${logs_dir}/\${jobid}\" 2>&1
    colorprint \"Check the following error log for more information:\"  \"red\" >> \"${logs_dir}/\${jobid}\" 2>&1
    colorprint \"\\\\\"${logs_dir}/\${jobid}_err\\\\\"\"                \"red\" >> \"${logs_dir}/\${jobid}\" 2>&1
fi
" > "${this_dir}/jobscript"
    # Check for the qsub command
    qsub_path="$(which qsub 2> /dev/null || :)"
    if [ -z "${qsub_path}" ]; then
        colorprint "Error: Could not find the 'qsub' command. Is PBS installed and on the PATH?" "red"
        exit 1
    fi
    # Submit the remote job from within the logs directory, so that autogenerated files will be dumped there
    jobid=$(cd "${logs_dir}" && qsub "${this_dir}/jobscript")
    jobid="${jobid%.in1}"
    colorprint "\nSubmitting job" "yellow"
    echo "Job ${jobid} submitted to queue ${queue}"
    echo "You can now kill (Ctrl-C) this script without cancelling the job"
    # Deactivate trap and call the watch script
    sleep 1
    trap : 0
    "${utilities_dir}/watch" "${jobid}"
else
    # Run locally.
    # Construct a jobid that does not conflict with the content of the logs dir
    jobid=0
    while :; do
        if [ ! -f "${logs_dir}/${jobid}" ]; then
            break
        fi
        ((jobid += 1))
    done
    # Print start message
    echo
    if [ "${pure_python}" == "True" ]; then
        colorprint "Running CONCEPT in pure Python mode" "yellow" | tee "${logs_dir}/${jobid}"
    else
        colorprint "Running CONCEPT" "yellow" | tee "${logs_dir}/${jobid}"
    fi
    echo "Entry point:   \"${main_rel}\""          | tee -a "${logs_dir}/${jobid}"
    echo "Parameterfile: \"${params_rel}\""        | tee -a "${logs_dir}/${jobid}"
    echo "Logfile:       \"${logs_dir}/${jobid}\"" | tee -a "${logs_dir}/${jobid}"
    echo "Nr. of CPUs:    ${nprocs}"               | tee -a "${logs_dir}/${jobid}"
    # Prepare Python options
    if [ "${pure_python}" == "True" ] ; then
        # Run as normal Python script
        main_as_library="${main}"
        m_flag=""
    else
        # Run as compiled library module
        main_as_library="$(basename "${main%.*}.so")"
        m_flag="-m"
    fi
    # Run the code. Print stdout and stderr to the terminal while at the
    # same time logging them to logs_dir/jobid. The stderr alone is also
    # logged to logs_dir/jobid_err.
    "${mpiexec}" -n "${nprocs}" "${python}" -B ${m_flag} "${main_as_library}" "params='${params}'" "scp_password='${scp_password}'" 2> >(tee -a "${logs_dir}/${jobid}_err") | tee -a "${logs_dir}/${jobid}"
    # Get exit status of the above CO𝘕CEPT run
    concept_exit_status="${PIPESTATUS[0]}"
    # Run complete. Remove error log if empty
    if [ -f "${logs_dir}/${jobid}_err" ] && [ ! -s "${logs_dir}/${jobid}_err" ]; then
        rm "${logs_dir}/${jobid}_err"
    else
        colorprint "\nSome warnings/errors occured during CONCEPT run!" "red" 2>&1 | tee -a "${logs_dir}/${jobid}"
        colorprint "Check the following error log for more information:" "red" 2>&1 | tee -a "${logs_dir}/${jobid}"
        colorprint "\"${logs_dir}/${jobid}_err\"" "red" 2>&1 | tee -a "${logs_dir}/${jobid}"
    fi
    # If the CO𝘕CEPT run exited erroneously, exit now
    if [ "${concept_exit_status}" != "0" ]; then
        exit 1
    fi
    # Deactivate trap before exiting
    trap : 0
fi
